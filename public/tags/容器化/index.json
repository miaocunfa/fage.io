[{"content":"更新记录    时间 内容     2021-08-06 初稿    软件版本    soft Version     zabbix server 4.0.32   zabbix agent 4.0.29    监控脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  ➜ vim /etc/zabbix/scripts/supervisor.sh #!/bin/bash # Describe: monitor supervisorctl status # Create Date： 2021-08-06 # Create Time: 17:06 # Update Date:  # Update Time:  # Author: MiaoCunFa # Version: v0.0.1 #=================================================================== file=/etc/zabbix/scripts/supervisor.txt # 值校验 if [ \u0026#34;$1\u0026#34; == \u0026#34;\u0026#34; ]; then Usage exit 0 fi function Usage(){ echo \u0026#34;Usage: supervisor.sh [programm]\u0026#34; } #=================================================================== sudo supervisorctl status \u0026gt; $file CMD=$(grep \u0026#34;$1\u0026#34; $file|awk \u0026#39;{print $2}\u0026#39;) if [ \u0026#34;$CMD\u0026#34; == \u0026#34;RUNNING\u0026#34; ]; then echo \u0026#34;1\u0026#34; else echo \u0026#34;0\u0026#34; fi # 执行权限 ➜ chmod u+x supervisor.sh ➜ touch supervisor.txt ➜ chown zabbix:zabbix supervisor* # 修改 zabbix conf ➜ vim /etc/zabbix/zabbix_agentd.d/supervisor.conf UserParameter=py_status[*], /bin/bash /etc/zabbix/scripts/supervisor.sh $1 # 修改 sudo 权限 ➜ vim /etc/sudoers zabbix ALL=NOPASSWD:/usr/bin/supervisorctl # 重启 zabbix agent 服务 ➜ systemctl restart zabbix-agent   测试验证 1 2  ➜ zabbix_get -s 192.168.189.193 -k py_status[prod_auto] 1   Zabbix UI ①创建模板\n点击 \u0026lsquo;配置\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;模板\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;创建模板\u0026rsquo;\n②创建应用集 big-prod-node1\n③创建监控项\n在模板下 \u0026ndash;\u0026gt; 点击 \u0026lsquo;监控项\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;创建监控项\u0026rsquo;\n④创建触发器\n在模板下 \u0026ndash;\u0026gt; 点击 \u0026lsquo;触发器\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;创建触发器\u0026rsquo;\nZabbix 验证 ①监控项列表\n②最新数据\n","description":"","id":0,"section":"ops","tags":["zabbix","告警","supervisorctl"],"title":"Zabbix 监控 supervisorctl","uri":"http://localhost:1818/ops/monitor/zabbix%E7%9B%91%E6%8E%A7supervisorctl/"},{"content":"更新记录    时间 内容     2021-07-23 初稿   2021-08-06 修改解决方法为sudo权限    软件版本    soft Version     zabbix server 4.0.32   zabbix agent 4.0.29    问题描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # 命令执行效果 ➜ supervisorctl status prod_auto RUNNING pid 16604, uptime 15 days, 0:24:23 prod_cycle RUNNING pid 16602, uptime 15 days, 0:24:23 prod_offline RUNNING pid 16605, uptime 15 days, 0:24:23 prod_one_to_one RUNNING pid 16598, uptime 15 days, 0:24:23 prod_online_orders RUNNING pid 16603, uptime 15 days, 0:24:23 prod_online_tables RUNNING pid 16601, uptime 15 days, 0:24:23 prod_server_list RUNNING pid 16597, uptime 15 days, 0:24:23 prod_server_manual RUNNING pid 16599, uptime 15 days, 0:24:23 prod_timer RUNNING pid 16600, uptime 15 days, 0:24:23 # 获取 python 程序执行状态 ➜ supervisorctl status | grep prod_auto | awk \u0026#39;{print $2}\u0026#39; RUNNING # 配置 supervisor.conf ➜ vim /etc/zabbix/zabbix_agentd.d/supervisor.conf UserParameter=py_status[*], supervisorctl status | grep $1 | awk \u0026#39;{print $2}\u0026#39;   Zabbix 配置好监控项以后无法获取数据\n问题解决 查到这个问题是因为 Zabbix在调用 supervisorctl 时试用 zabbix 用户执行没有权限，\n解决办法是给 zabbix 用户加 sudo 权限\n1 2  ➜ vim /etc/sudoers zabbix ALL=NOPASSWD:/usr/bin/supervisorctl    参考文档：\n[1] centos环境下使用zabbix配合python脚本对supervisor中的进程运行状态进行监控\n[2] 修改sudo权限\n[3] Zabbix远程命令权限不足问题解决方法\n ","description":"","id":1,"section":"ops","tags":["zabbix","告警","supervisorctl"],"title":"Zabbix 解决 supervisorctl 无法获取值","uri":"http://localhost:1818/ops/monitor/zabbix%E8%A7%A3%E5%86%B3supervisor%E6%97%A0%E6%B3%95%E8%8E%B7%E5%8F%96%E5%80%BC/"},{"content":"更新信息    时间 内容     2021-06-04 初稿    软件版本    时间 内容     2021-06-04 初稿    安装 ①下载安装包 \u0026amp;\u0026amp; 安装\n1 2 3 4 5 6 7 8  # 三台主机都执行 ➜ unzip rabbitMQ3.7.7.zip ➜ cd rabbitMQ3.7.7 # 安装 ➜ yum install erlang-21.3.8.6-1.el7.x86_64.rpm ➜ yum install rabbitmq-server-3.7.7-1.el7.noarch.rpm   ②查看安装文件路径\n1 2 3 4 5 6 7 8 9  ➜ rpm -ql rabbitmq-server-3.7.7-1.el7.noarch /etc/logrotate.d/rabbitmq-server /etc/profile.d/rabbitmqctl-autocomplete.sh /etc/rabbitmq /usr/lib/ocf/resource.d/rabbitmq/rabbitmq-server /usr/lib/ocf/resource.d/rabbitmq/rabbitmq-server-ha /usr/lib/rabbitmq/autocomplete/bash_autocomplete.sh /usr/lib/rabbitmq/autocomplete/zsh_autocomplete.sh /usr/lib/rabbitmq/bin/cuttlefish   配置 ①host文件\n1 2 3 4 5 6 7  # 三台主机都执行 ➜ vim /etc/hosts # rabbitMQ 192.168.31.30 MQ1 192.168.31.104 MQ2 192.168.31.155 MQ3   ②创建持久化目录\n1 2 3 4 5  # 三台主机都执行 ➜ mkdir -p /disk2/rabbitmq/{store,logs} ➜ cd /disk2 ➜ chown -R rabbitmq:rabbitmq rabbitmq/   ③rabbit配置文件\n1 2 3 4 5 6 7 8 9  ➜ vim /etc/rabbitmq/rabbitmq-env.conf # 指定节点的名字，默认rabbit@${hostname} NODENAME=rabbit@MQ1 # 指定端口，默认5672 NODE_PORT=5672 # 配置持久目录 MNESIA_BASE=/disk2/rabbitmq/store # 配置日志目录 默认文件名字：${NODENAME}.log 可以用配置修改 LOG_BASE=/disk2/rabbitmq/logs   启动服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  ➜ systemctl start rabbitmq-server ➜ systemctl status rabbitmq-server ● rabbitmq-server.service - RabbitMQ broker Loaded: loaded (/usr/lib/systemd/system/rabbitmq-server.service; disabled; vendor preset: disabled) Active: active (running) since Fri 2021-06-04 16:16:18 CST; 36s ago Main PID: 13071 (beam.smp) Status: \u0026#34;Initialized\u0026#34; Tasks: 127 Memory: 57.7M CGroup: /system.slice/rabbitmq-server.service ├─13071 /usr/lib64/erlang/erts-10.3.5.4/bin/beam.smp -W w -A 96 -MBas ageffcbf -MHas ageffcbf -MBlmbcs 512 -MHlmbcs 512 -MMmcs 30 -P 1048576 -t 5000000 -stbt db -zdbbl 1280000... ├─13212 /usr/lib64/erlang/erts-10.3.5.4/bin/epmd -daemon ├─13419 erl_child_setup 1024 ├─13446 inet_gethost 4 └─13447 inet_gethost 4 Jun 04 16:16:16 master rabbitmq-server[13071]: ## ## Jun 04 16:16:16 master rabbitmq-server[13071]: ## ## RabbitMQ 3.7.7. Copyright (C) 2007-2018 Pivotal Software, Inc. Jun 04 16:16:16 master rabbitmq-server[13071]: ########## Licensed under the MPL. See http://www.rabbitmq.com/ Jun 04 16:16:16 master rabbitmq-server[13071]: ###### ## Jun 04 16:16:16 master rabbitmq-server[13071]: ########## Logs: /disk2/rabbitmq/logs/rabbit@MQ1.log Jun 04 16:16:16 master rabbitmq-server[13071]: /disk2/rabbitmq/logs/rabbit@MQ1_upgrade.log Jun 04 16:16:16 master rabbitmq-server[13071]: Starting broker... Jun 04 16:16:18 master rabbitmq-server[13071]: systemd unit for activation check: \u0026#34;rabbitmq-server.service\u0026#34; Jun 04 16:16:18 master systemd[1]: Started RabbitMQ broker. Jun 04 16:16:18 master rabbitmq-server[13071]: completed with 0 plugins.   集群 ①erlang.cookie\nyum部署的rabbitmq, .erlang.cookie 在 /var/lib/rabbitmq 下\n1 2 3 4 5 6 7 8  ➜ cat /var/lib/rabbitmq/.erlang.cookie DGXKRZAJARTBMFEXIRGV ➜ scp .erlang.cookie root@MQ2:/var/lib/rabbitmq ➜ scp .erlang.cookie root@MQ3:/var/lib/rabbitmq # 在MQ2、MQ3执行 ➜ cd /var/lib/rabbitmq/; chown -R rabbitmq:rabbitmq ./.erlang.cookie   ②加入集群\n1 2 3 4 5 6 7 8 9  # MQ2 ➜ rabbitmqctl stop_app ➜ rabbitmqctl join_cluster rabbit@MQ1 ➜ rabbitmqctl start_app # MQ3 ➜ rabbitmqctl stop_app ➜ rabbitmqctl join_cluster rabbit@MQ1 --ram ➜ rabbitmqctl start_app   WEB管理 1 2 3  ➜ rabbitmq-plugins enable rabbitmq_management ➜ rabbitmqctl add_user gongjiangren-test gongjiangrenQAWSED@@ ➜ rabbitmqctl set_user_tags gongjiangren-test administrator   1 2 3 4  ➜ ss -tnlp|grep 5672 LISTEN 0 128 *:25672 *:* users:((\u0026#34;beam.smp\u0026#34;,pid=13071,fd=65)) LISTEN 0 128 *:15672 *:* users:((\u0026#34;beam.smp\u0026#34;,pid=13071,fd=80)) LISTEN 0 128 [::]:5672 [::]:* users:((\u0026#34;beam.smp\u0026#34;,pid=13071,fd=76))   ","description":"","id":2,"section":"ops","tags":["消息队列","rabbit MQ"],"title":"yum部署rabbitMQ集群","uri":"http://localhost:1818/ops/deploy/yum%E9%83%A8%E7%BD%B2rabbitmq%E9%9B%86%E7%BE%A4/"},{"content":"更新记录    时间 内容     2021-04-02 初稿    软件版本    soft Version     zabbix server 4.0.21   zabbix agent 4.0.29    引言 现在越来越多的浏览器要求你使用SSL证书，google浏览器直接不允许访问非SSL证书认证的网站，所以现在下公司SSL证书越来越多，这就带来了一个问题，如果SSL证书过期了，会非常影响用户体验。\n所以结合公司正在使用的Zabbix监控告警平台，提前告知SSL证书即将过期，将对管理SSL证书非常有效。\nZabbix Agent 自动发现脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  ➜ vim /etc/zabbix/scripts/ssl_discover.py #!/usr/bin/python \u0026#34;\u0026#34;\u0026#34; Created by Vscode. File: OpsNotes:ssl_discover.py User: miaocunfa Create Date: 2021-04-02 Create Time: 16:08 Update Date: 2021-04-02 Update Time: 17:04 Version: v0.0.3 \u0026#34;\u0026#34;\u0026#34; import os import json # 返回证书列表 def discover(): d = {} d[\u0026#39;data\u0026#39;] = [] with os.popen(\u0026#34;cd /usr/local/nginx/conf/https/; ls *.crt\u0026#34;) as pipe: for line in pipe: info = {} info[\u0026#39;{#CRTFILE}\u0026#39;] = line.replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;) d[\u0026#39;data\u0026#39;].append(info) print(json.dumps(d)) discover() # 执行脚本 返回如下json ➜ python3 ssl_discover.py {\u0026#34;data\u0026#34;: [{\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_api.gongjiangren.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_api.qixinbao.net.cn_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_api.shengshui.com_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_api.tt321.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_fleetin.gongjiangren.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_front.gongjiangren.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_market.gongjiangren.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_website.page.gongjiangren.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_www.gongjiangren.net_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_www.qixinbao.net.cn_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_www.shengshui.com_bundle.crt\u0026#34;}, {\u0026#34;{#CRTFILE}\u0026#34;: \u0026#34;1_yqfk.gongjiangren.net_bundle.crt\u0026#34;}]}   监控脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  ➜ vim /etc/zabbix/scripts/ssl_check.sh #!/bin/bash # Describe: ssl_check.sh # Create Date： 2021-04-02 # Create Time: 15:48 # Update Date: 2021-04-02 # Update Time: 16:59 # Author: MiaoCunFa # Version: v0.0.4 #=================================================================== function Usage(){ echo \u0026#34;Usage: ssl_check [crtfile] [alertday]\u0026#34; } crtfile=$1 alert_date=$2 crtdir=\u0026#34;/usr/local/nginx/conf/https\u0026#34; if [ \u0026#34;$1\u0026#34; == \u0026#34;\u0026#34; ]; then Usage exit 0 fi if [ \u0026#34;$2\u0026#34; == \u0026#34;\u0026#34; ]; then Usage exit 0 fi #=================================================================== cd $crtdir # 过期时间 \u0026amp;\u0026amp; 过期时间时间戳 expire_date=$(openssl x509 -in $crtfile -noout -text | grep \u0026#34;Not After\u0026#34; | awk -F \u0026#34; : \u0026#34; \u0026#39;{print $2}\u0026#39;) expire_stamp=$(date -d \u0026#34;$expire_date\u0026#34; +%s) # 提醒日期 \u0026amp;\u0026amp; 提醒日期时间戳 alert_stamp=$(($expire_stamp - $alert_date * 86400)) # 当前日期 \u0026amp;\u0026amp; 当前日期时间戳 curdate_stamp=$(date +%s) #curdate_stamp=$(date --date 20210823 +%s) # 判断当期日期与提醒日期 if [ $curdate_stamp -ge $alert_stamp ]; then echo 1 else echo 0 fi   配置文件 1 2 3  ➜ vim /etc/zabbix/zabbix_agentd.d/ssl.conf UserParameter=ssl.discovery,python3 /etc/zabbix/scripts/ssl_discover.py UserParameter=ssl.check[*],/bin/bash /etc/zabbix/scripts/ssl_check.sh $1 $2   执行权限 \u0026amp;\u0026amp; agent重启 1 2 3 4 5  ➜ cd /etc/zabbix/scripts ➜ chown -R zabbix:zabbix ssl* ➜ chmod u+x ssl* ➜ systemctl restart zabbix-agent   Zabbix UI 1、创建模板\n点击 \u0026lsquo;配置\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;模板\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;创建模板\u0026rsquo;\n2、创建自动发现\n选择模板 \u0026ndash;\u0026gt; 点击\u0026rsquo;自动发现' \u0026ndash;\u0026gt; \u0026lsquo;创建发现规则\u0026rsquo;\n3、创建监控项原型\n在自动发现规则下 \u0026ndash;\u0026gt; 点击 \u0026lsquo;监控项原型\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;创建监控项原型\u0026rsquo;\n4、创建触发器\n在自动发现规则下 \u0026ndash;\u0026gt; 点击 \u0026lsquo;触发器类型\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;创建触发器原型\u0026rsquo;\n5、主机添加模板\n点击 \u0026lsquo;配置\u0026rsquo; \u0026ndash;\u0026gt; 选择\u0026rsquo;主机' \u0026ndash;\u0026gt; 点击\u0026rsquo;模板' \u0026ndash;\u0026gt; 选择\u0026rsquo;模板\u0026rsquo;添加\n6、验证数据\n点击 \u0026lsquo;监测\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;最新数据\u0026rsquo; \u0026ndash;\u0026gt; 选择\u0026rsquo;主机\u0026rsquo;与\u0026rsquo;应用集' \u0026ndash;\u0026gt; \u0026lsquo;应用\u0026rsquo;\n7、报警信息\n 参考文档：\n[1] SSL证书到期时间监控提醒工具+脚本推荐\n[2] 监控域名HTTPS证书过期时间\n[3] 查看域名https证书到期时间\n[4] Shell日期时间和时间戳的转换\n ","description":"","id":3,"section":"ops","tags":["zabbix","ssl证书"],"title":"Zabbix 监控 SSL证书","uri":"http://localhost:1818/ops/monitor/zabbix%E7%9B%91%E6%8E%A7ssl%E8%AF%81%E4%B9%A6/"},{"content":"更新记录    时间 内容     2021-03-15 初稿    软件版本    soft Version     zabbix server 4.0.21   zabbix agent 4.0.29   ansible 2.9.17    一、Zabbix agent 1.1、zabbix agent 配置 ➜ vim /etc/zabbix/zabbix_agentd.d/docker.conf\rUserParameter=docker.discovery,python3 /etc/zabbix/scripts/docker_monitor.py\rUserParameter=docker.[*],python3 /etc/zabbix/scripts/docker_monitor.py $1 $2\r1.2、python 监控脚本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  ➜ vim /etc/zabbix/scripts/docker_monitor.py #!/usr/bin/python \u0026#34;\u0026#34;\u0026#34; Created by PyCharm. File: OpsNotes:docker_monitor.py User: miaocunfa Create Date: 2021-03-12 Create Time: 17:10 Update Date: 2021-03-12 Update Time: 17:10 Version: v0.0.1 \u0026#34;\u0026#34;\u0026#34; import sys import os import json # 返回容器列表 def discover(): d = {} d[\u0026#39;data\u0026#39;] = [] with os.popen(\u0026#34;docker ps -a --format {{.Names}}\u0026#34;) as pipe: for line in pipe: info = {} info[\u0026#39;{#CONTAINERNAME}\u0026#39;] = line.replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;) d[\u0026#39;data\u0026#39;].append(info) print(json.dumps(d)) def status(name,action): # 判断容器运行状态 if action == \u0026#34;ping\u0026#34;: cmd = \u0026#39;docker inspect --format=\u0026#34;{{.State.Running}}\u0026#34; %s\u0026#39; %name result = os.popen(cmd).read().replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;) if result == \u0026#34;true\u0026#34;: print(1) else: print(0) # 网络收包 elif action == \u0026#34;network_rx_bytes\u0026#34;: cmd = \u0026#34;\u0026#34;\u0026#34;docker exec %scat /proc/net/dev|sed -n 3p|awk \u0026#39;{print $2,$10}\u0026#39;\u0026#34;\u0026#34;\u0026#34; %name result = os.popen(cmd).read().split()[0] print(result) # 网络发包 elif action == \u0026#34;network_tx_bytes\u0026#34;: cmd = \u0026#34;\u0026#34;\u0026#34;docker exec %scat /proc/net/dev|sed -n 3p|awk \u0026#39;{print $2,$10}\u0026#39;\u0026#34;\u0026#34;\u0026#34; %name result = os.popen(cmd).read().split()[1] print(result) # 使用 docker stats 命令获得容器指标 else: cmd = \u0026#39;docker stats %s--no-stream --format \u0026#34;{{.%s}}\u0026#34;\u0026#39; % (name,action) result = os.popen(cmd).read().replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;) if \u0026#34;%\u0026#34; in result: print(float(result.replace(\u0026#34;%\u0026#34;,\u0026#34;\u0026#34;))) else: print(result) if __name__ == \u0026#39;__main__\u0026#39;: try: name, action = sys.argv[1], sys.argv[2] status(name,action) except IndexError: discover()   1.3、推送到服务器 1 2 3  ➜ ansible docker -m copy -a \u0026#34;src=/root/ansible/docker.conf dest=/etc/zabbix/zabbix_agentd.d/\u0026#34; ➜ ansible docker -m copy -a \u0026#34;src=/root/ansible/docker_monitor.py dest=/etc/zabbix/scripts/\u0026#34; ➜ ansible docker -m shell -a \u0026#34;systemctl restart zabbix-agent\u0026#34;   二、Zabbix Server 打开链接，导入 此模板\n点击 \u0026lsquo;配置\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;模板\u0026rsquo; \u0026ndash;\u0026gt; 找到对应模板 \u0026ndash;\u0026gt; \u0026lsquo;自动发现\u0026rsquo; \u0026ndash;\u0026gt; \u0026lsquo;监控项原型\u0026rsquo;\n三、问题解决 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  # 使用 docker.discovery 获取 Docker 列表 # zabbix 用户无法访问 /var/run/docker.sock ➜ zabbix_get -s 192.168.189.180 -p 10050 -k docker.discovery Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/json?all=1: dial unix /var/run/docker.sock: connect: permission denied # 查看 docker.sock 的权限 # docker.sock 文件 属主root、属组docker ➜ ansible docker -m shell -a \u0026#34;ls -rtl /var/run/docker.sock\u0026#34; [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details 192.168.189.175 | CHANGED | rc=0 \u0026gt;\u0026gt; srw-rw---- 1 root docker 0 Oct 10 2019 /var/run/docker.sock 192.168.189.177 | CHANGED | rc=0 \u0026gt;\u0026gt; srw-rw---- 1 root docker 0 Oct 10 2019 /var/run/docker.sock 192.168.189.178 | CHANGED | rc=0 \u0026gt;\u0026gt; srw-rw---- 1 root docker 0 Oct 10 2019 /var/run/docker.sock 192.168.189.171 | CHANGED | rc=0 \u0026gt;\u0026gt; srw-rw---- 1 root docker 0 Oct 10 2019 /var/run/docker.sock 192.168.189.176 | CHANGED | rc=0 \u0026gt;\u0026gt; srw-rw---- 1 root docker 0 Oct 10 2019 /var/run/docker.sock 192.168.189.180 | CHANGED | rc=0 \u0026gt;\u0026gt; srwxr-xr-x 1 root docker 0 Oct 10 2019 /var/run/docker.sock # 将 zabbix 用户加入 docker组 # 重启 zabbix-agent 服务以生效 ➜ ansible docker -m shell -a \u0026#34;usermod -a -G docker zabbix\u0026#34; ➜ ansible docker -m shell -a \u0026#34;systemctl restart zabbix-agent\u0026#34; # 获取到 Docker 列表 ➜ zabbix_get -s 192.168.189.180 -p 10050 -k docker.discovery {\u0026#34;data\u0026#34;: [{\u0026#34;{#CONTAINERNAME}\u0026#34;: \u0026#34;V_Prod_Bidding_Two\u0026#34;}, {\u0026#34;{#CONTAINERNAME}\u0026#34;: \u0026#34;V_Prod_Machine_Two\u0026#34;}, {\u0026#34;{#CONTAINERNAME}\u0026#34;: \u0026#34;V_Prod_Order_Two\u0026#34;}, {\u0026#34;{#CONTAINERNAME}\u0026#34;: \u0026#34;V_Prod_Project_One\u0026#34;}, {\u0026#34;{#CONTAINERNAME}\u0026#34;: \u0026#34;V_Prod_Three_One\u0026#34;}, {\u0026#34;{#CONTAINERNAME}\u0026#34;: \u0026#34;V_Prod_School_One\u0026#34;}]}   四、验证数据 检测 \u0026ndash;\u0026gt; 最新数据 \u0026ndash;\u0026gt; 应用集选 \u0026lsquo;docker_monitor\u0026rsquo;\n 参考文档：\n[1] zabbix自发现实时监控docker容器及容器中各个服务的状态线上业务展示\n[2] zabbix监控docker容器状态\n ","description":"","id":4,"section":"ops","tags":["zabbix","告警","docker"],"title":"Zabbix 监控docker容器","uri":"http://localhost:1818/ops/monitor/zabbix%E7%9B%91%E6%8E%A7docker%E5%AE%B9%E5%99%A8/"},{"content":"1、复制 conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # openvpn 的 systemd Unit ➜ cat /usr/lib/systemd/system/openvpn@.service [Unit] Description=OpenVPN Robust And Highly Flexible Tunneling Application On %I After=network.target [Service] Type=notify PrivateTmp=true ExecStart=/usr/sbin/openvpn --cd /etc/openvpn/ --config %i.conf # 只要在/etc/openvpn/目录下编辑好配置文件，启动时指定配置文件名即可启动。 [Install] WantedBy=multi-user.target ➜ cd /etc/openvpn ➜ cp server.conf server-tcp.conf ➜ vim server-tcp.conf port 57678 proto tcp # 需修改为tcp dev tun ca /etc/openvpn/server/certs/ca.crt cert /etc/openvpn/server/certs/server.crt key /etc/openvpn/server/certs/server.key dh /etc/openvpn/server/certs/dh.pem tls-auth /etc/openvpn/server/certs/ta.key 0 crl-verify /etc/openvpn/easy-rsa/3/pki/crl.pem server 10.8.0.0 255.255.255.0 push \u0026#34;dhcp-option DNS 8.8.8.8\u0026#34; push \u0026#34;dhcp-option DNS 8.8.4.4\u0026#34; push \u0026#34;route 172.19.0.0 255.255.0.0\u0026#34; compress lzo keepalive 10 120 comp-lzo persist-key persist-tun user openvpn group openvpn log /var/log/openvpn/server-tcp.log # 需与 udp 区分 log-append /var/log/openvpn/server-tcp.log # 需与 udp 区分 status /var/log/openvpn/status-tcp.log # 需与 udp 区分 verb 3 # explicit-exit-notify 1 # 需禁用   2、启动 tcp server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 启动服务 \u0026amp;\u0026amp; 查看状态 ➜ systemctl start openvpn@server-tcp ➜ systemctl status openvpn@server-tcp ● openvpn@server-tcp.service - OpenVPN Robust And Highly Flexible Tunneling Application On server/tcp Loaded: loaded (/usr/lib/systemd/system/openvpn@.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2020-08-17 10:15:31 CST; 4s ago Main PID: 6501 (openvpn) Status: \u0026#34;Initialization Sequence Completed\u0026#34; CGroup: /system.slice/system-openvpn.slice/openvpn@server-tcp.service └─6501 /usr/sbin/openvpn --cd /etc/openvpn/ --config server-tcp.conf Aug 17 10:15:31 zax.aihangxunxi.com systemd[1]: Starting OpenVPN Robust And Highly Flexible Tunneling Application On server/tcp... Aug 17 10:15:31 zax.aihangxunxi.com systemd[1]: Started OpenVPN Robust And Highly Flexible Tunneling Application On server/tcp. # 同时启动 tcp、udp ➜ ss -nlp|grep 57678 udp UNCONN 0 0 *:57678 *:* users:((\u0026#34;openvpn\u0026#34;,pid=5437,fd=5)) tcp LISTEN 0 32 *:57678 *:* users:((\u0026#34;openvpn\u0026#34;,pid=6501,fd=5))   3、客户端 ovpn文件 # 配置ovpn文件连接 tcp协议\rD:\\Program Files\\OpenVPN\\config\\miaocunfa-tcp.ovpn\rclient\rproto tcp\rdev tun\rremote [公网IP] 57678\rca ca.crt\rcert miaocunfa.crt\rkey miaocunfa.key\rtls-auth ta.key 1\rremote-cert-tls server\rpersist-tun\rpersist-key\rcomp-lzo\rverb 3\rmute-replay-warnings\r4、报错 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 没禁用 explicit-exit-notify 选项 # 启动报错 ➜ systemctl start openvpn@server-tcp Job for openvpn@server-tcp.service failed because the control process exited with error code. See \u0026#34;systemctl status openvpn@server-tcp.service\u0026#34; and \u0026#34;journalctl -xe\u0026#34; for details. ➜ systemctl status openvpn@server-tcp ● openvpn@server-tcp.service - OpenVPN Robust And Highly Flexible Tunneling Application On server/tcp Loaded: loaded (/usr/lib/systemd/system/openvpn@.service; enabled; vendor preset: disabled) Active: failed (Result: exit-code) since Mon 2020-08-17 10:11:34 CST; 7s ago Process: 5749 ExecStart=/usr/sbin/openvpn --cd /etc/openvpn/ --config %i.conf (code=exited, status=1/FAILURE) Main PID: 5749 (code=exited, status=1/FAILURE) Aug 17 10:11:34 zax.aihangxunxi.com systemd[1]: Starting OpenVPN Robust And Highly Flexible Tunneling Application On server/tcp... Aug 17 10:11:34 zax.aihangxunxi.com systemd[1]: openvpn@server-tcp.service: main process exited, code=exited, status=1/FAILURE Aug 17 10:11:34 zax.aihangxunxi.com systemd[1]: Failed to start OpenVPN Robust And Highly Flexible Tunneling Application On server/tcp. Aug 17 10:11:34 zax.aihangxunxi.com systemd[1]: Unit openvpn@server-tcp.service entered failed state. Aug 17 10:11:34 zax.aihangxunxi.com systemd[1]: openvpn@server-tcp.service failed. # 查看日志 ➜ cat server-tcp.log Options error: --explicit-exit-notify can only be used with --proto udp Use --help for more information.   ","description":"","id":5,"section":"ops","tags":["OpenVPN"],"title":"OpenVPN使用tcp协议","uri":"http://localhost:1818/ops/network/openvpn%E4%BD%BF%E7%94%A8tcp%E5%8D%8F%E8%AE%AE/"},{"content":"更新记录    时间 内容     2020-07-28 初稿   2020-07-29 增加systemd服务    环境    Server Version     Seata 1.3.0   CentOS 7.6   Redis 3.2.12   Consul v1.5.3    概述 Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。\n一、下载 1 2 3 4 5 6 7  # 下载 seata安装包 ➜ wget https://github.com/seata/seata/releases/download/v1.3.0/seata-server-1.3.0.tar.gz ➜ tar zxf seata-server-1.3.0.tar.gz -C /opt # 将安装包拷贝至另外两个节点 ➜ scp seata-server-1.3.0.tar.gz n222:/opt ➜ scp seata-server-1.3.0.tar.gz n225:/opt   二、配置 Seata 的高可用依赖于注册中心、配置中心和数据库来实现\n2.1、注册中心 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ➜ cd /opt/seata/conf ➜ vim registry.conf registry { # 注册中心指定为consul type = \u0026#34;consul\u0026#34; consul { cluster = \u0026#34;default\u0026#34; serverAddr = \u0026#34;192.168.100.223:8500\u0026#34; } } config { # 配置中心指定为文件 type = \u0026#34;file\u0026#34; file { name = \u0026#34;file.conf\u0026#34; } }   2.2、数据库 2.2.1、db 配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 修改存储为 db ➜ vim file.conf store { mode = \u0026#34;db\u0026#34; db { datasource = \u0026#34;druid\u0026#34; dbType = \u0026#34;postgresql\u0026#34; driverClassName = \u0026#34;org.postgresql.Driver\u0026#34; url = \u0026#34;jdbc:postgresql://192.168.100.241:9999/seata\u0026#34; user = \u0026#34;postgres\u0026#34; password = \u0026#34;test%123\u0026#34; minConn = 5 maxConn = 30 globalTable = \u0026#34;global_table\u0026#34; branchTable = \u0026#34;branch_table\u0026#34; lockTable = \u0026#34;lock_table\u0026#34; queryLimit = 100 maxWait = 5000 } }   postgre SQL\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  -- Server -- Create database Seata CREATEDATABASEseata;-- the table to store GlobalSession data DROPTABLEIFEXISTS\u0026#34;global_table\u0026#34;;CREATETABLE\u0026#34;global_table\u0026#34;(\u0026#34;xid\u0026#34;VARCHAR(128)NOTNULL,\u0026#34;transaction_id\u0026#34;INT8,\u0026#34;status\u0026#34;INT4NOTNULL,\u0026#34;application_id\u0026#34;VARCHAR(100),\u0026#34;transaction_service_group\u0026#34;VARCHAR(100),\u0026#34;transaction_name\u0026#34;VARCHAR(128),\u0026#34;timeout\u0026#34;INT4,\u0026#34;begin_time\u0026#34;INT8,\u0026#34;application_data\u0026#34;text,\u0026#34;gmt_create\u0026#34;TIMESTAMP,\u0026#34;gmt_modified\u0026#34;TIMESTAMP,PRIMARYKEY(\u0026#34;xid\u0026#34;));CREATEINDEXON\u0026#34;global_table\u0026#34;(\u0026#34;gmt_modified\u0026#34;,\u0026#34;status\u0026#34;);CREATEINDEXON\u0026#34;global_table\u0026#34;(\u0026#34;transaction_id\u0026#34;);-- the table to store BranchSession data DROPTABLEIFEXISTS\u0026#34;branch_table\u0026#34;;CREATETABLE\u0026#34;branch_table\u0026#34;(\u0026#34;branch_id\u0026#34;INT8NOTNULL,\u0026#34;xid\u0026#34;VARCHAR(128)NOTNULL,\u0026#34;transaction_id\u0026#34;INT8,\u0026#34;resource_group_id\u0026#34;VARCHAR(100),\u0026#34;resource_id\u0026#34;VARCHAR(256),\u0026#34;lock_key\u0026#34;VARCHAR(128),\u0026#34;branch_type\u0026#34;VARCHAR(8),\u0026#34;status\u0026#34;INT4,\u0026#34;client_id\u0026#34;VARCHAR(100),\u0026#34;application_data\u0026#34;text,\u0026#34;gmt_create\u0026#34;TIMESTAMP,\u0026#34;gmt_modified\u0026#34;TIMESTAMP,PRIMARYKEY(\u0026#34;branch_id\u0026#34;));CREATEINDEXON\u0026#34;branch_table\u0026#34;(\u0026#34;xid\u0026#34;);-- the table to store lock data DROPTABLEIFEXISTS\u0026#34;lock_table\u0026#34;;CREATETABLE\u0026#34;lock_table\u0026#34;(\u0026#34;row_key\u0026#34;VARCHAR(128)NOTNULL,\u0026#34;xid\u0026#34;VARCHAR(100),\u0026#34;transaction_id\u0026#34;INT8,\u0026#34;branch_id\u0026#34;INT8,\u0026#34;resource_id\u0026#34;VARCHAR(256),\u0026#34;table_name\u0026#34;VARCHAR(100),\u0026#34;pk\u0026#34;VARCHAR(100),\u0026#34;gmt_create\u0026#34;TIMESTAMP,\u0026#34;gmt_modified\u0026#34;TIMESTAMP,PRIMARYKEY(\u0026#34;row_key\u0026#34;));-- Client -- the sequence of undo_log CREATESEQUENCEundo_log_id_seqSTART1INCREMENT1;DROPTABLEIFEXISTS\u0026#34;undo_log\u0026#34;;CREATETABLE\u0026#34;undo_log\u0026#34;(\u0026#34;id\u0026#34;INT8NOTNULLDEFAULTnextval(\u0026#39;undo_log_id_seq\u0026#39;),\u0026#34;branch_id\u0026#34;INT8NOTNULL,\u0026#34;xid\u0026#34;VARCHAR(100)NOTNULL,\u0026#34;context\u0026#34;VARCHAR(128)NOTNULL,\u0026#34;rollback_info\u0026#34;BYTEANOTNULL,\u0026#34;log_status\u0026#34;INT4NOTNULL,\u0026#34;log_created\u0026#34;TIMESTAMP,\u0026#34;log_modified\u0026#34;TIMESTAMP,\u0026#34;ext\u0026#34;VARCHAR(100)DEFAULTNULL,PRIMARYKEY(\u0026#34;id\u0026#34;),UNIQUE(\u0026#34;branch_id\u0026#34;,\u0026#34;xid\u0026#34;));  2.2.2、redis 配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 修改存储为 redis ➜ vim file.conf store { mode = \u0026#34;redis\u0026#34; redis { host = \u0026#34;192.168.100.223\u0026#34; port = \u0026#34;6379\u0026#34; password = \u0026#34;\u0026#34; database = \u0026#34;0\u0026#34; minConn = 1 maxConn = 10 queryLimit = 100 } }   安装redis\n1 2 3 4 5 6 7 8 9  # 安装 redis ➜ yum install -y redis # 修改配置文件 ➜ vim /etc/redis.conf bind 0.0.0.0 # 启动 redis ➜ systemctl start redis   三、启动 3.1、启动选项 启动选项：\r-h: 注册到注册中心的ip\r-p: Server rpc 监听端口\r-m: 全局事务会话信息存储模式，file、db、redis，优先读取启动参数 (Seata-Server 1.3及以上版本支持redis)\r-n: Server node，多个Server时，需区分各自节点，用于生成不同区间的transactionId，以免冲突\r-e: 多环境配置参考 http://seata.io/en-us/docs/ops/multi-configuration-isolation.html\r3.2、脚本启动 1 2 3 4 5 6 7 8  # n222 ➜ sh ./bin/seata-server.sh -n 1 # n223 ➜ sh ./bin/seata-server.sh -n 2 # n225 ➜ sh ./bin/seata-server.sh -n 3   3.3、注册为systemd服务 systemd 服务脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ➜ vim /usr/lib/systemd/system/seata@.service [Unit] Description=The Seata Server After=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=simple ExecStart=/bin/sh -c \u0026#39;/opt/seata/bin/seata-server.sh -n %i \u0026gt; /opt/seata/logs/seata-%i.log 2\u0026gt;\u0026amp;1\u0026#39; Restart=always ExecStop=/usr/bin/kill -15 $MAINPID KillSignal=SIGTERM KillMode=mixed PrivateTmp=true [Install] WantedBy=multi-user.target   启动服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ➜ systemctl daemon-reload ➜ systemctl start seata@3 ➜ systemctl status seata@3 ● seata@3.service - The Seata Server Loaded: loaded (/usr/lib/systemd/system/seata@.service; disabled; vendor preset: disabled) Active: active (running) since Wed 2020-07-29 08:43:43 CST; 1s ago Main PID: 17960 (sh) CGroup: /system.slice/system-seata.slice/seata@3.service ├─17960 /bin/sh -c /opt/seata/bin/seata-server.sh -n 3 2\u0026gt;\u0026amp;1 \u0026gt; /opt/seata/logs/seata-3.log └─17961 /usr/bin/java -server -Xmx2048m -Xms2048m -Xmn1024m -Xss512k -XX:SurvivorRatio=10 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m -XX:MaxDirectMemorySize=1024m -XX:-O... Jul 29 08:43:43 node225 systemd[1]: Started The Seata Server. Jul 29 08:43:45 node225 sh[17960]: log4j:WARN No appenders could be found for logger (org.apache.http.client.protocol.RequestAddCookies). Jul 29 08:43:45 node225 sh[17960]: log4j:WARN Please initialize the log4j system properly. Jul 29 08:43:45 node225 sh[17960]: log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info. ➜ cd /opt/seata/logs/ ➜ ll total 32 -rw-r--r-- 1 root root 28037 Jul 29 08:46 seata-3.log -rw-r--r-- 1 root root 986 Jul 29 08:44 seata_gc.log    参考链接:\n1、Seata直接部署文档\n2、Seata高可用部署\n3、Seata参数配置\n4、七步带你集成Seata 1.2 高可用搭建\n5、Seata GitHub\n6、Systemd 入门教程：实战篇\n7、systemctl服务编写，及日志控制\n8、linux kill信号列表\n ","description":"","id":6,"section":"ops","tags":["seata","分布式事务"],"title":"部署高可用seata","uri":"http://localhost:1818/ops/deploy/%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8seata/"},{"content":"更新记录    时间 内容     2020-07-15 初稿   2020-07-21 编译etcdhelper   2020-07-23 完成图床的替换    环境    Server Version     etcdctl 3.3.15   API 3.3    一、概述 etcd 是一个响应快、分布式、一致的 key-value 存储\n二、操作 2.1、进入etcd容器 1 2 3 4 5 6 7 8 9 10 11 12 13  # 获取etcd pod ➜ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE etcd-apiserver.cluster.local 1/1 Running 9 40d # exec进入etcd内 ➜ kubectl exec -n kube-system etcd-apiserver.cluster.local -it -- /bin/sh # 容器内etcd的目录结构 # find / -name \u0026#39;etcd\u0026#39; -print /etc/kubernetes/pki/etcd # 证书目录 /usr/local/bin/etcd # 二进制程序 /var/lib/etcd # 数据目录   2.2、etcdctl etcd3 API 从kubernetes 1.6开始，etcd集群使用version 3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # 下载etcdctl, 以在etcd容器外访问etcd接口 # https://github.com/etcd-io/etcd/releases ➜ cp etcdctl /usr/local/bin/ # 设置API版本为3 # 必须先指定API的版本才能使用 --cert等参数指定证书, api2的参数与3不一致。 ➜ export ETCDCTL_API=3 # 指定证书获取 endpoint的状态 ➜ etcdctl --endpoints=https://localhost:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key endpoint health https://localhost:2379 is healthy: successfully committed proposal: took = 2.706905334s # 可以声明 etcdctl的环境变量 ➜ vim /etc/profile # etcd export ETCDCTL_API=3 export ETCDCTL_DIAL_TIMEOUT=3s; export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt; export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt; export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key; export ETCD_ENDPOINTS=https://localhost:2379 ➜ source /etc/profile # 可以不用指定证书了 ➜ etcdctl endpoint health 127.0.0.1:2379 is healthy: successfully committed proposal: took = 827.031484ms   三、Kubernetes资源 3.1、etcdctl ls脚本 v3版本的数据存储没有目录层级关系了，而是采用平展（flat)模式，换句话说/a与/a/b并没有嵌套关系，而只是key的名称差别而已，这个和AWS S3以及OpenStack Swift对象存储一样，没有目录的概念，但是key名称支持/字符，从而实现看起来像目录的伪目录，但是存储结构上不存在层级关系。\n也就是说etcdctl无法使用类似v2的ls命令。但是我还是习惯使用v2版本的etcdctl ls查看etcdctl存储的内容，于是写了个性能不怎么好但是可以用的shell脚本etcd_ls.sh:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  ➜ vim etcd_ls.sh #!/bin/bash PREFIX=${1:-/} ORIG_PREFIX=${PREFIX} LAST_CHAR=${PREFIX:${#PREFIX}-1:1} if [[ $LAST_CHAR != \u0026#39;/\u0026#39; ]]; then # Append \u0026#39;/\u0026#39; at the end if not exist PREFIX=\u0026#34;$PREFIX/\u0026#34; fi for ITEM in $(etcdctl get \u0026#34;$PREFIX\u0026#34; --prefix=true --keys-only | grep \u0026#34;$PREFIX\u0026#34;); do PREFIX_LEN=${#PREFIX} CONTENT=${ITEM:$PREFIX_LEN} POS=$(expr index \u0026#34;$CONTENT\u0026#34; \u0026#39;/\u0026#39;) if [[ $POS -le 0 ]]; then # No \u0026#39;/\u0026#39;, it\u0026#39;s not dir, get whole str POS=${#CONTENT} fi CONTENT=${CONTENT:0:$POS} LAST_CHAR=${CONTENT:${#CONTENT}-1:1} if [[ $LAST_CHAR == \u0026#39;/\u0026#39; ]]; then CONTENT=${CONTENT:0:-1} fi echo ${PREFIX}${CONTENT} done | sort | uniq   3.2、获取所有key 由于Kubernetes的所有数据都以/registry为前缀，因此首先查看/registry\n我们发现除了minions、range等大多数资源都可以通过etcdctl get xxx获取，组织格式为/registry/{resource_name}/{namespace}/{resource_instance}，而minions其实就是node信息，Kubernetes之前节点叫minion，应该还没有改过来，因此还是使用的/registry/minions\n3.3、获取key值 如上为什么需要使用strings命令，那是因为除了/registry/apiregistration.k8s.io是直接存储JSON格式的，其他资源默认都不是使用JSON格式直接存储，而是通过protobuf格式存储，当然这么做的原因是为了性能，除非手动配置\u0026ndash;storage-media-type=application/json，参考: etcdctl v3: k8s changes its internal format to proto, and the etcdctl result is unreadable.\n直接查看会乱码\n四、etcdhelper 使用proto提高了性能，但也导致有时排查问题时不方便直接使用etcdctl读取内容，可幸的是openshift项目已经开发了一个强大的辅助工具 etcdhelper 可以读取etcd内容并解码proto。\n4.1、编译etcdhelper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  # 源代码url # https://github.com/openshift/origin/blob/master/tools/etcdhelper/etcdhelper.go # 编译 # 使用gomod编译etcdhelper ➜ go mod init etcdhelper go: creating new go.mod: module etcdhelper ➜ go test ➜ cat go.mod module etcdhelper go 1.14 require ( github.com/coreos/etcd v3.3.22+incompatible // indirect github.com/coreos/pkg v0.0.0-20180928190104-399ea9e2e55f // indirect github.com/openshift/api v0.0.0-20200714125145-93040c6967eb go.etcd.io/etcd v3.3.22+incompatible go.uber.org/zap v1.15.0 // indirect k8s.io/apimachinery v0.18.6 k8s.io/kubectl v0.18.6 ) # 正常情况下，go test之后就可以进行编译了，报错了需要先解决错误。 ➜ go build etcdhelper.go go: finding module for package github.com/coreos/go-systemd/journal /root/go/pkg/mod/github.com/coreos/etcd@v3.3.22+incompatible/pkg/logutil/zap_journal.go:29:2: no matching versions for query \u0026#34;latest\u0026#34; # 这个问题主要看这个 [issues](https://github.com/etcd-io/etcd/issues/11345) # 先将 go-systemd 下载到本地 ➜ mkdir -p $GOPATH/src/github.com/coreos/go-systemd/ ➜ git clone https://github.com/coreos/go-systemd.git $GOPATH/src/github.com/coreos/go-systemd/ ➜ cd $myproject # 修改 go.mod，将依赖改为本地包 ➜ vim go.mod replace ( github.com/coreos/go-systemd =\u0026gt; github.com/coreos/go-systemd/v22 latest ) # 再执行go test ➜ go test # 执行编译，并生成可执行文件etcdhelper ➜ go build etcdhelper.go ➜ ll total 46668 -rwxr-xr-x. 1 root root 47737965 Jul 20 15:59 etcdhelper -rw-r--r--. 1 root root 4988 Jul 16 17:00 etcdhelper.go -rwxr--r--. 1 root root 706 Jul 16 16:45 etcd_ls.sh -rw-r--r--. 1 root root 515 Jul 20 15:54 go.mod -rw-r--r--. 1 root root 32493 Jul 20 15:54 go.sum   4.2、使用etcdhelper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # 将etcdhelper 加入PATH ➜ mv etcdhelper $HOME/go/bin # Usage ➜ ./etcdhelper -h Usage of ./etcdhelper: -cacert string Server TLS CA certificate. -cert string TLS client certificate. -endpoint string etcd endpoint. (default \u0026#34;https://127.0.0.1:2379\u0026#34;) -key string TLS client key. # 设置别名 ➜ alias etcdhelper=\u0026#39;etcdhelper -cacert /etc/kubernetes/pki/etcd/ca.crt \\ -key /etc/kubernetes/pki/etcd/server.key \\ -cert /etc/kubernetes/pki/etcd/server.crt\u0026#39;   获取key值，现在可以看到存储在etcd中JSON格式的数据了\n 参考链接：\n1、unable to retrive registry from etcd-3.0.4\n2、https://www.jianshu.com/p/dbb0623a541d\n3、etcd官网\n4、https://github.com/etcd-io/etcd/blob/master/Documentation/dev-guide/interacting_v3.md\n5、etcd3如何设置环境变量\n6、如何读取Kubernetes存储在etcd上的数据\n ","description":"","id":7,"section":"cloudnative","tags":["Kubernetes","容器化","etcd"],"title":"Kubernetes之etcd操作","uri":"http://localhost:1818/cloudnative/kubernetes/kubernetes%E4%B9%8Betcd%E6%93%8D%E4%BD%9C/"},{"content":"1、查看哪些证书被吊销 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  ➜ cd /etc/openvpn/easy-rsa/3/pki ➜ openssl crl -in crl.pem -text -noout Certificate Revocation List (CRL): Version 2 (0x1) Signature Algorithm: sha256WithRSAEncryption Issuer: /CN=OpenVPN Last Update: Jun 23 03:09:23 2020 GMT Next Update: Dec 20 03:09:23 2020 GMT CRL extensions: X509v3 Authority Key Identifier: keyid:0B:FC:91:BF:E1:6E:F6:C7:57:73:1C:2B:75:2B:92:92:03:34:67:D5 DirName:/CN=OpenVPN serial:B1:B4:E0:A6:AC:A2:46:B2 Revoked Certificates: # 已吊销证书 Serial Number: 44CB5112DF5B2506DAD198ACC0E34642 Revocation Date: May 17 02:08:44 2020 GMT Serial Number: 54911ECB78462C7F0A05D8E727FFF9A1 Revocation Date: May 17 02:13:38 2020 GMT Serial Number: A1043A93E4CEDCB501447E173CDE80B4 Revocation Date: May 17 02:11:15 2020 GMT Serial Number: B263F59B7EA19DD2930D0E9B8A7FFAEA Revocation Date: May 17 02:13:26 2020 GMT Serial Number: C4DE65A0079E8B25FF13758BA1222418 Revocation Date: Jun 23 03:08:10 2020 GMT Signature Algorithm: sha256WithRSAEncryption 04:e6:e9:d5:13:f4:1d:0e:8b:87:5a:35:16:49:53:9a:7e:90: dc:bb:09:49:c8:69:cc:56:40:96:e9:0a:f9:c3:56:19:25:a5: c7:ed:16:d3:0d:a4:26:a2:56:c4:ed:e3:6c:f4:56:e8:e3:eb: 9d:ff:a8:31:eb:3b:7a:9f:b2:af:c0:96:ce:9b:46:08:3c:2e: cc:5e:63:59:e4:e9:72:bb:3e:e2:cf:9e:b4:40:f9:80:e2:d0: 41:b3:91🆎fb:0d:1d:75:f8:7a:1c:5c:ba:dc:95:0a:bb:42: 19:8b:d4:51:89:19:c5:4b:93:07:e5:3c:c1:1a:fd:06:7b:b7: d6:13:af:3b:ce:13:42:7f:1f:d9:b9:0a:5d:5c:d4:73:c8:1a: b0:0a:1d:00:b0:02:70:b8:6e:6d:a7:b4:79:6a:e8:5e:1f:fe: f2:2c:5a:da:eb:8e:f0:bf:95:86:0d:6b:85:b5:30:f7:99:bb: d6:74:a5:4a:7e:8c:48:20:63:9b:af:21:00:ba:55:0d:3a:59: 14:60:d0:05:e9:25:07:fd:53:22:05:fc:b0:4b:7b:32:2a:e9: 0a:eb:57:7d:c9:17:d5:fd:20:71:61:6b:03:28:ba:b9:0d:fe: d3:5b:72:1d:21:75:e7:52:8a:a6:fc:81:8c:31:ea:42:ff:0d: 46:51:16:84   2、pki/index.txt文件 可理解为openvpn客户端的数据库\n所有生成的openvpn客户端证书记录(可用、吊销)\n文件中通过第一列标志识别是否为注销状态\nV为可用\nR为注销\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  ➜ cat index.txt V 221209013920Z 4046594A6432AD1597EE47EB6E00DD8F unknown /CN=server V 221209023107Z A82D845FF707408BB05049D4BF9CAF41 unknown /CN=wangshuxian V 221209052534Z 4661B64B6B934B2C6EE94C55FF5CDF47 unknown /CN=server V 221209070724Z 601EDFDA6E1FE245D92CC0C881416FE1 unknown /CN=test V 221209070729Z 55CE3FD4A111C086840FDC6776EBCBC9 unknown /CN=test2 V 221209070733Z 7924CC116FAE0D7BC90C93E51D102E3E unknown /CN=test3 V 221209092037Z 2922DD807C81B72B48BFD400E253958B unknown /CN=chenqingze V 221210013225Z EE173E515FA302F75067F2BFC070FD25 unknown /CN=wangchaochao R 221210075931Z 200517021326Z B263F59B7EA19DD2930D0E9B8A7FFAEA unknown /CN=zhangyan V 221210081023Z 401455EFD27C8187923032FA09D78DB0 unknown /CN=chujiao R 221210092059Z 200517021115Z A1043A93E4CEDCB501447E173CDE80B4 unknown /CN=liuzhangbin V 221210145608Z E2BFFD9921752954394D799AF91426E5 unknown /CN=wanghongchao R 230103065628Z 200517021338Z 54911ECB78462C7F0A05D8E727FFF9A1 unknown /CN=liuzhangbin2 R 230222082718Z 200517020844Z 44CB5112DF5B2506DAD198ACC0E34642 unknown /CN=zhangliling V 230608031249Z 732FF079AA63D180070E91326F9550E2 unknown /CN=miaocunfa   3、crl.pem说明 该文件为吊销证书的名单，配合 pki/index.txt 识别客户端是否可用。\n若未在 server.conf 中配置该文件，即使吊销客户端证书后客户端仍可以正常连接。\n1 2  ➜ vim /etc/openvpn/server.conf crl-verify /etc/openvpn/easy-rsa/3/pki/crl.pem   4、吊销过程 1 2 3 4 5 6 7 8 9 10  # 1、使用./easyrsa注销证书 # 此时只是更新index.txt标识为R(注销)，但经实践后发现标识为R的客户端，仍可以正常连接服务端。 ➜ ./easyrsa revoke $USER # 2、更新crl.pem文件 # 并将该文件配置在server.conf中 ➜ ./easyrsa gen-crl # 3、重启openvpn server ➜ systemctl restart openvpn@server   5、几个常见问题 5.1、吊销证书仍可连接 使用./easyrsa revoke $USER 吊销客户端证书后，客户端仍可以连上服务端\n解决方法\n1 2 3  ➜ vim /etc/openvpn/server.conf crl-verify /etc/openvpn/easy-rsa/3/pki/crl.pem ➜ ./easyrsa gen-crl   5.2、无法读取crl.pem 服务端日志报错，无法读取crl.pem内容\n解决方法：\n1  ➜ chmod 600 /etc/openvpn/easy-rsa/3/pki/crl.pem    参考文章:\n1、http://www.wallcopper.com/linux/3197.html\n ","description":"","id":8,"section":"ops","tags":["OpenVPN"],"title":"OpenVPN吊销证书不生效","uri":"http://localhost:1818/ops/network/openvpn%E5%90%8A%E9%94%80%E8%AF%81%E4%B9%A6%E4%B8%8D%E7%94%9F%E6%95%88/"},{"content":"更新信息    时间 内容     2020-03-25 初稿   2020-08-05 文档结构优化   2020-08-12 增加插件列表    版本信息 rabbit MQ: 3.8.2\rErlang: 官方建议最低21.3 推荐22.x\r这里用的是22.2.8\r一、环境准备 1.1、主机规划    主机 节点     192.168.100.217 磁盘节点   192.168.100.218 内存节点   192.168.100.219 磁盘节点    内存节点：\r内存节点将所有的队列、交换机、绑定、用户、权限和 vhost 的元数据定义存储在内存中，好处是可以使得像交换机和队列声明等操作更加的快速。例外情况是：持久的 queue 的内容将被保存到磁盘。\r磁盘节点：\r将元数据存储在磁盘中，单节点系统只允许磁盘类型的节点，防止重启 RabbitMQ 的时候，丢失系统的配置信息。\r注意点：\r1、内存节点由于不进行磁盘读写，它的性能比磁盘节点高。\r2、集群中可以存在多个磁盘节点，磁盘节点越多整个集群可用性越好，但是集群整体性能不会线性增加，需要权衡考虑。\r3、RabbitMQ 要求在集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。如果集群中唯一的一个磁盘节点崩溃的话，集群仍然可以保持运行，但是无法进行其他操作（增删改查），直到节点恢复。\r4、设置两个磁盘节点，至少有一个是可用的，可以保存元数据的更改。\r1.2、下载离线包 官网安装手册\n1 2 3 4 5  rabbit MQ：二进制版 ➜ wget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.8.2/rabbitmq-server-generic-unix-3.8.2.tar.xz Erlang: 无依赖版 -- 该软件包剥离了一些Erlang模块和依赖项，这些对运行RabbitMQ而言不是必需的。 ➜ wget https://github.com/rabbitmq/erlang-rpm/releases/download/v22.2.8/erlang-22.2.8-1.el7.x86_64.rpm   1.3、安装离线包 1 2 3 4 5 6  # 安装erlang ➜ yum install -y yum install erlang-22.2.8-1.el7.x86_64.rpm # 解压rabbitmq ➜ xz -d rabbitmq-server-generic-unix-3.8.2.tar.xz ➜ tar -xvf rabbitmq-server-generic-unix-3.8.2.tar -C /opt   1.4、hosts文件 1 2 3  192.168.100.217 MQ1 192.168.100.218 MQ2 192.168.100.219 MQ3   1.5、配置文件 我们要自己在$Home/etc/rabbitmq中创建rabbitmq-env.conf, 详细信息请参阅 官方配置说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 创建持久化目录 ➜ mkdir -p /ahdata/rabbitmq/store ➜ mkdir -p /ahdata/rabbitmq/logs # 创建配置文件 ➜ vim /opt/rabbitmq_server-3.8.2/etc/rabbitmq/rabbitmq-env.conf # 指定节点的名字，默认rabbit@${hostname} NODENAME=rabbit@MQ1 # 指定端口，默认5672 NODE_PORT=5672 # 配置持久目录 MNESIA_BASE=/ahdata/rabbitmq/store # 配置日志目录 默认文件名字：${NODENAME}.log 可以用配置修改 LOG_BASE=/ahdata/rabbitmq/logs   二、启用服务 2.1、常用命令 1 2 3 4 5 6 7 8 9 10  ➜ sbin/rabbitmq-server # 启动server ➜ sbin/rabbitmq-server -detached # 后台启动server ➜ sbin/rabbitmqctl status # 查看节点状态 ➜ sbin/rabbitmqctl shutdown # 停止运行的节点 ➜ sbin/rabbitmqctl stop_app ➜ sbin/rabbitmqctl start_app ➜ sbin/rabbitmqctl cluster_status # 查看集群状态 ➜ sbin/rabbitmqctl set_cluster_name rabbit@MQ1 # 修改集群名称 ➜ sbin/rabbitmqctl join_cluster \u0026lt;cluster_name\u0026gt; # 加入集群 ➜ sbin/rabbitmqctl change_cluster_node_type --node \u0026lt;node_name\u0026gt; [ disk | ram ] # 修改节点类型   2.2、启动rabbit 1 2 3 4 5  ➜ cd /opt/rabbitmq_server-3.8.2/ ➜ sbin/rabbitmq-server -detached # 查看节点状态 ➜ sbin/rabbitmqctl status   2.3、erlang.cookie Erlang 节点间通过认证 Erlang cookie 的方式允许互相通信。因为 rabbitmqctl 使用 Erlang OTP 通信机制来和 Rabbit 节点通信，运行 rabbitmqctl 的机器和所要连接的 Rabbit 节点必须使用相同的 Erlang cookie 。否则你会得到一个错误。\n1 2 3 4 5 6  ➜ cat /root/.erlang.cookie IJPCAHDPWVYSDERZDUPG # 保持cookie一致 ➜ scp /root/.erlang.cookie n218:/root/.erlang.cookie ➜ scp /root/.erlang.cookie n219:/root/.erlang.cookie   现在三台机器上具有相同的 Erlang cookie 了。下面开始组建集群。\n三、集群 3.1、基础概念 RabbitMQ 集群分为两种:\n 普通集群 镜像集群(普通集群的升级)  普通集群：\n以两个节点（rabbit01、rabbit02）为例来进行说明。\rrabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构，但消息实体只存在于其中一个节点rabbit01（或者rabbit02）中。当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。当rabbit01节点故障后，rabbit02节点无法取到rabbit01节点中还未消费的消息实体。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。\r镜像集群：\n在普通集群的基础上，把需要的队列做成镜像队列，消息实体会主动在镜像节点间同步，而不是在客户端取数据时临时拉取，也就是说多少节点消息就会备份多少份。该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。所以在对可靠性要求较高的场合中适用。由于镜像队列之间消息自动同步，且内部有选举master机制，即使master节点宕机也不会影响整个集群的使用，达到去中心化的目的，从而有效的防止消息丢失及服务不可用等问题。\r3.2、普通集群 3.2.1、集群名 将集群名修改为rabbit@MQ1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # 修改集群名 ➜ sbin/rabbitmqctl set_cluster_name rabbit@MQ1 Setting cluster name to rabbit@MQ1 ... # 查看集群状态 ➜ sbin/rabbitmqctl cluster_status Cluster status of node rabbit@MQ1 ... Basics Cluster name: rabbit@MQ1 Disk Nodes rabbit@MQ1 Running Nodes rabbit@MQ1   3.2.2、加入集群 在218、219节点上执行\n1 2 3  ➜ sbin/rabbitmqctl stop_app ➜ sbin/rabbitmqctl join_cluster rabbit@MQ1 ➜ sbin/rabbitmqctl start_app   3.2.3、修改节点类型 查看集群状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ➜ sbin/rabbitmqctl cluster_status Cluster status of node rabbit@MQ1 ... Basics Cluster name: rabbit@MQ1 Disk Nodes # 磁盘节点 rabbit@MQ1 # 我们看到所有的节点都是disk类型与我们预设的架构不符 rabbit@MQ2 # 我们需要修改一下这个架构 rabbit@MQ3 Running Nodes rabbit@MQ1 rabbit@MQ2 rabbit@MQ3   更改218节点为内存节点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # 停止节点 ➜ sbin/rabbitmqctl stop_app # 与集群通讯，从集群中删除节点 ➜ sbin/rabbitmqctl reset # 以RAM模式重新加入集群 ➜ sbin/rabbitmqctl join_cluster rabbit@MQ1 --ram # 启动节点 ➜ sbin/rabbitmqctl start_app ➜ sbin/rabbitmqctl cluster_status Cluster status of node rabbit@MQ1 ... Basics Cluster name: rabbit@MQ1 Disk Nodes rabbit@MQ1 rabbit@MQ3 RAM Nodes rabbit@MQ2 Running Nodes rabbit@MQ1 rabbit@MQ2 rabbit@MQ3   节点单机状态时，reset 命令将清空节点的状态，并将其恢复到空白状态。当节点是集群的一部分时，该命令也会和集群中的磁盘节点通信，告诉他们该节点正在离开集群。\n这很重要，不然，集群会认为该节点出了故障，并期望其最终能够恢复回来，在该节点回来之前，集群禁止新的节点加入。\n3.3、镜像集群(HA) 上面我们已经成功部署了一个普通集群，普通集群并不是高可用的，下面基于普通集群升级为镜像集群\n官方HA方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ➜ sbin/rabbitmqctl set_policy \u0026lt;name\u0026gt; [-p \u0026lt;vhost\u0026gt;] \u0026lt;pattern\u0026gt; \u0026lt;definition\u0026gt; [--apply-to \u0026lt;apply-to\u0026gt;] name: 策略名称 vhost: 指定vhost, 默认值 / pattern: 通过正则表达式匹配哪些需要镜像, ^为所有 definition: ha-mode: 指明镜像队列的模式，有效值为 all/exactly/nodes all 表示在集群所有的节点上进行镜像，无需设置ha-params exactly 表示在指定个数的节点上进行镜像，节点的个数由ha-params指定 nodes 表示在指定的节点上进行镜像，节点名称通过ha-params指定 ha-params: ha-mode 模式需要用到的参数 ha-sync-mode: 镜像队列中消息的同步方式，有效值为automatic，manually apply-to: 策略作用对象。可选值3个，默认all exchanges 表示镜像 exchange (并不知道意义所在) queues 表示镜像 queue all 表示镜像 exchange和queue ➜ sbin/rabbitmqctl set_policy ahy \u0026#34;^\u0026#34; \u0026#39;{\u0026#34;ha-mode\u0026#34;:\u0026#34;all\u0026#34;,\u0026#34;ha-sync-mode\u0026#34;:\u0026#34;automatic\u0026#34;}\u0026#39;      ha-mode ha-params 功能     all 空 镜像队列将会在整个集群中复制。当一个新的节点加入后，也会在这 个节点上复制一份。   exactly count 镜像队列将会在集群上复制 count 份。如果集群数量少于 count 时候，队列会复制到所有节点上。如果大于 Count 集群，有一个节点 crash 后，新进入节点也不会做新的镜像。   nodes node name 镜像队列会在 node name 中复制。如果这个名称不是集群中的一个，这不会触发错误。如果在这个 node list 中没有一个节点在线，那么这个 queue 会被声明在 client 连接的节点。    四、WEB管理 4.1、启用WEB管理插件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  # 启动web管理插件 ➜ sbin/rabbitmq-plugins enable rabbitmq_management # 启用插件列表 ➜ sbin/rabbitmq-plugins list Listing plugins with pattern \u0026#34;.*\u0026#34; ... Configured: E = explicitly enabled; e = implicitly enabled | Status: * = running on rabbit@ty-db1 |/ [ ] rabbitmq_amqp1_0 3.8.2 [ ] rabbitmq_auth_backend_cache 3.8.2 [ ] rabbitmq_auth_backend_http 3.8.2 [ ] rabbitmq_auth_backend_ldap 3.8.2 [ ] rabbitmq_auth_backend_oauth2 3.8.2 [ ] rabbitmq_auth_mechanism_ssl 3.8.2 [ ] rabbitmq_consistent_hash_exchange 3.8.2 [ ] rabbitmq_event_exchange 3.8.2 [ ] rabbitmq_federation 3.8.2 [ ] rabbitmq_federation_management 3.8.2 [ ] rabbitmq_jms_topic_exchange 3.8.2 [E*] rabbitmq_management 3.8.2 # E 显式启用 [e*] rabbitmq_management_agent 3.8.2 # e 隐式启用 # 增加用户 \u0026amp;\u0026amp; 设置用户角色 ➜ sbin/rabbitmqctl add_user ahy ahy # 执行一遍 ➜ sbin/rabbitmqctl set_user_tags ahy administrator # 执行一遍   4.2、访问管理界面 1 2 3 4  ➜ ss -tnlp | grep 5672 LISTEN 0 128 *:25672 *:* users:((\u0026#34;beam.smp\u0026#34;,pid=3593,fd=77)) LISTEN 0 128 *:15672 *:* users:((\u0026#34;beam.smp\u0026#34;,pid=3593,fd=93)) LISTEN 0 128 :::5672 :::* users:((\u0026#34;beam.smp\u0026#34;,pid=3593,fd=92))   打开浏览器访问http://nodeip:15672, 使用上面创建的用户登录即可\n五、负载均衡 我们这里用haproxy做负载均衡\n5.1、增加VIP 1 2 3 4 5 6 7 8 9  ➜ ip addr add 192.168.100.242/24 dev eth0:mq ➜ ip a 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 5a:fd:bf:c3:43:ec brd ff:ff:ff:ff:ff:ff inet 192.168.100.217/24 brd 192.168.100.255 scope global noprefixroute eth0 valid_lft forever preferred_lft forever inet 192.168.100.242/24 scope global secondary eth0 valid_lft forever preferred_lft forever   5.2、配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  ➜ vim /opt/rabbitmq_server-3.8.2/etc/haproxy.cnf global log 127.0.0.1 local0 info log 127.0.0.1 local1 notice daemon maxconn 4096 defaults log global mode tcp option tcplog option dontlognull retries 3 option abortonclose maxconn 4096 timeout connect 5000ms timeout client 3000ms timeout server 3000ms balance roundrobin listen private_monitoring bind 192.168.100.242:8100 mode http option httplog stats refresh 5s stats uri /stats stats realm Haproxy stats auth admin:admin listen rabbitmq_cluster bind 192.168.100.242:8101 mode tcp option tcplog balance roundrobin server MQ1 192.168.100.217:5672 check inter 5000 rise 2 fall 3 server MQ2 192.168.100.218:5672 check inter 5000 rise 2 fall 3 server MQ3 192.168.100.219:5672 check inter 5000 rise 2 fall 3 listen rabbitmq_admin bind 192.168.100.242:8102 server MQ1 192.168.100.217:15672 server MQ2 192.168.100.218:15672 server MQ3 192.168.100.219:15672   5.3、启动haproxy 1  ➜ haproxy -f /opt/rabbitmq_server-3.8.2/etc/haproxy.cnf    参考链接:\n1、官方二进制手册\n2、官方集群手册\n3、https://www.jianshu.com/p/97fbf9c82872\n4、https://my.oschina.net/genghz/blog/1840262\n5、https://www.jianshu.com/p/d55fcee12918\n6、https://www.jianshu.com/p/7cf2ad01c422\n7、https://blog.csdn.net/yujin2010good/article/details/73614507\n8、http://www.haproxy.org/\n9、https://blog.csdn.net/winy_lm/article/details/81128181\n10、https://www.cnblogs.com/knowledgesea/p/6535766.html\n ","description":"","id":9,"section":"ops","tags":["消息队列","rabbit MQ","haproxy"],"title":"部署rabbitMQ镜像集群","uri":"http://localhost:1818/ops/deploy/%E9%83%A8%E7%BD%B2rabbitmq%E9%95%9C%E5%83%8F%E9%9B%86%E7%BE%A4/"},{"content":"一、环境准备 1 2 3 4  $ wget https://github.com/strapdata/elassandra/releases/download/v6.2.3.22/elassandra-6.2.3.22.tar.gz $ tar -zxvf elassandra-6.2.3.22.tar.gz $ useradd elassandra $ chown -R elassandra:elassandra elassandra-6.2.3.22   二、配置部署 2.1、目录结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ su - elassandra #切换用户 $ cd /opt/elassandra-6.2.3.22 #进入工作路径 $ ls -rtl total 264 -rw-r--r--. 1 elassandra elassandra 12319 Dec 11 17:51 README.md -rw-r--r--. 1 elassandra elassandra 11358 Dec 11 17:51 LICENSE.txt -rw-r--r--. 1 elassandra elassandra 21612 Dec 11 17:51 CHANGES.txt -rw-r--r--. 1 elassandra elassandra 194935 Dec 11 18:19 NOTICE.txt drwxr-xr-x. 2 elassandra elassandra 6 Dec 11 18:20 plugins drwxr-xr-x. 3 elassandra elassandra 94 Dec 11 18:20 pylib drwxr-xr-x. 4 elassandra elassandra 135 Dec 11 18:20 tools drwxr-xr-x. 16 elassandra elassandra 4096 Dec 11 18:20 modules drwxr-xr-x. 4 elassandra elassandra 4096 Jan 2 00:39 lib drwxr-xr-x. 2 elassandra elassandra 4096 Jan 2 00:39 bin drwxr-xr-x. 3 elassandra elassandra 4096 Jan 2 02:30 conf drwxr-xr-x. 6 elassandra elassandra 68 Jan 2 02:33 data drwxr-xr-x. 2 elassandra elassandra 48 Jan 2 03:19 logs   2.2、修改limits.conf文件 1 2 3 4  $ vi /etc/security/limits.conf # allow user \u0026#39;elassandra\u0026#39; mlockall elassandra soft memlock unlimited elassandra hard memlock unlimited   2.3、修改.bash_profile文件 1 2 3 4  $ vi ~/.bash_profile export CASSANDRA_HOME=/opt/elassandra-6.2.3.22 export CASSANDRA_CONF=/opt/elassandra-6.2.3.22/conf $ source ~/.bash_profile   2.4、Cassandra配置文件 1 2 3 4 5 6 7 8 9  $ cat cassandra.yaml | grep -v ^# | grep -v ^$ cluster_name: \u0026#39;Test Cluster\u0026#39; seed_provider: - class_name: org.apache.cassandra.locator.SimpleSeedProvider parameters: - seeds: \u0026#34;192.168.100.217\u0026#34; listen_address: 192.168.100.217 rpc_address: 192.168.100.217 endpoint_snitch: GossipingPropertyFileSnitch   2.5、删除cassandra拓扑 该文件存在时GossipingPropertyFileSnitch始终加载cassandra-topology.properties\n1  $ mv cassandra-topology.properties topology   三、启动验证 3.1、启动 1 2 3  # -e 选项启动 elasticsearch, 否则只启动 cassandra # -f 选项启动在前台, 否则启动在后台 $ bin/cassandra -e -f   3.2、验证 1 2 3 4 5 6 7  $ bin/nodetool status Datacenter: DC1 =============== Status=Up/Down |/ State=Normal/Leaving/Joining/Moving -- Address Load Tokens Owns (effective) Host ID Rack UN 192.168.100.217 70.86 KiB 8 100.0% 3eca39ee-614e-44be-8dc3-24a57e258588 r1    参考文档：\n1、https://www.strapdata.com/blog/?__hstc=45866619.604d7d24da3130719d6ad13e1d96868c.1577946442157.1577946442157.1577946442157.1\u0026amp;__hssc=45866619.1.1577946442157\u0026amp;__hsfp=156548688\u0026amp;_ga=2.21459963.1978597677.1577946441-1461110499.1577946441\n2、https://medium.com/rahasak/deploy-multi-data-center-elassandra-cluster-c6cb4abf50d1\n3、http://opensourceforu.com/2017/07/elassandra-to-leverage-huge-data-stack/\n ","description":"","id":10,"section":"ops","tags":["elasticsearch","Cassandra","elassandra","搜索引擎","服务部署"],"title":"部署使用elassandra","uri":"http://localhost:1818/ops/deploy/%E9%83%A8%E7%BD%B2elassandra/"},{"content":"首先讲一下使用OpenVPN能给我们带来什么\n1、内网穿透是说你回到家中，通过开辟一条加密隧道，直接在家里访问公司内网，跟你在公司访问内部服务一个效果。\n2、公网穿透是说使用加密隧道访问公司生产网络，这样做带来的好处是我们可以将暴露在互联网上的大部分端口封掉，使用内网的方式访问生产，可以保证我们的网络安全。\n以上说的穿透主要基于NAT网络地址转换。\n我们在CentOS7下安装OpenVPN，OpenVPN使用以下版本\neasy-rsa.noarch 0:3.0.6-1.el7\ropenvpn.x86_64 0:2.4.8-1.el7\r一、部署 OpenVPN 1.1、关闭selinux 1 2  ➜ setenforce 0 ➜ sed -i \u0026#39;/^SELINUX=/c\\SELINUX=disabled\u0026#39; /etc/selinux/config   1.2、添加EPEL扩展库 1 2 3 4 5 6 7  ➜ /etc/yum.repos.d/aliyun.repo [aliyun-epel] name=aliyun-epel-CentOS$releasever enabled=1 baseurl=http://mirrors.aliyun.com/epel/$releasever/$basearch/ gpgcheck=1 gpgkey=http://mirrors.aliyun.com/epel/RPM-GPG-KEY-EPEL-7   1.3、安装所需依赖软件包 1  ➜ yum install -y openssl openssl-devel lzo lzo-devel pam pam-devel automake pkgconfig   1.4、安装OpenVPN和Easy-Rsa 1  ➜ yum -y install openvpn easy-rsa   1.5、将easy-rsa拷贝至openvpn下 1  ➜ cp -r /usr/share/easy-rsa/ /etc/openvpn/   二、配置 OpenVPN 2.1、openvpn程序树状图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ➜ tree openvpn openvpn ├── client ├── easy-rsa │ ├── 3 -\u0026gt; 3.0.6 │ ├── 3.0 -\u0026gt; 3.0.6 │ └── 3.0.6 │ ├── easyrsa │ ├── openssl-easyrsa.cnf │ └── x509-types │ ├── ca │ ├── client │ ├── code-signing │ ├── COMMON │ ├── server │ └── serverClient └── server   2.2、生成CA根证书 1 2 3 4 5 6 7 8 9 10 11  ➜ cd /etc/openvpn/easy-rsa/3.0.6/ ➜ vim vars export CA_EXPIRE=\u0026#34;3650\u0026#34; # 定义CA证书的有效期，默认是3650天，即10年。 export KEY_EXPIRE=\u0026#34;3650\u0026#34; # 定义密钥的有效期，默认是3650天，即10年。 export KEY_COUNTRY=\u0026#34;CN\u0026#34; # 定义所在的国家。 export KEY_PROVINCE=\u0026#34;ShanDong\u0026#34; # 定义所在的省份。 export KEY_CITY=\u0026#34;JiNan\u0026#34; # 定义所在的城市。 export KEY_ORG=\u0026#34;AiHangYun\u0026#34; # 定义所在的组织。 export KEY_EMAIL=\u0026#34;i@miaocf.com\u0026#34; # 定义邮箱地址。 export KEY_OU=\u0026#34;AH_OPS\u0026#34; # 定义所在的单位。 export KEY_NAME=\u0026#34;ZAX_Server\u0026#34; # 定义openvpn服务器的名称。   初始化环境变量\n1  ➜ source ./vars   生成服务器端CA证书根证书ca.crt和根密钥ca.key，由于在vars文件中做过缺省设置，在出现交互界面时，直接一路回车即可\n1 2  ➜ ./easyrsa init-pki ➜ ./easyrsa build-ca   为服务端生成证书和密钥(一路按回车，直到提示需要输入y/n时，输入y再按回车，一共两次)\n1  ➜ ./easyrsa build-server-full server nopass   2.3、生成 Diffie-Hellman 算法需要的密钥文件, 生成过程较慢 1  ➜ ./easyrsa gen-dh   2.4、生成 tls-auth key 这个 key 主要用于防止 DoS 和 TLS 攻击，这一步其实是可选的，但为了安全还是生成一下，该文件在后面配置 open VPN 时会用到。\n1  ➜ openvpn --genkey --secret ta.key   2.5、证书整理 将上面生成的相关证书文件整理到 /etc/openvpn/server/certs\n1 2 3 4 5 6  ➜ mkdir /etc/openvpn/server/certs \u0026amp;\u0026amp; cd /etc/openvpn/server/certs/ ➜ cp /etc/openvpn/easy-rsa/3/pki/dh.pem ./ # SSL 协商时 Diffie-Hellman 算法需要的 key ➜ cp /etc/openvpn/easy-rsa/3/pki/ca.crt ./ # CA 根证书 ➜ cp /etc/openvpn/easy-rsa/3/pki/issued/server.crt ./ # open VPN 服务器证书 ➜ cp /etc/openvpn/easy-rsa/3/pki/private/server.key ./ # open VPN 服务器证书 key ➜ cp /etc/openvpn/easy-rsa/3/ta.key ./ # tls-auth key   2.6、创建 open VPN 日志目录 1 2  ➜ mkdir -p /var/log/openvpn/ ➜ chown openvpn:openvpn /var/log/openvpn   2.7、配置 OpenVPN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  ➜ cat /etc/openvpn/server.conf port 57678 # 监听的端口号 proto udp # 服务端用的协议，udp 能快点，所以我选择 udp dev tun ca /etc/openvpn/server/certs/ca.crt # CA 根证书路径 cert /etc/openvpn/server/certs/server.crt # OpenVPN 服务器证书路径 key /etc/openvpn/server/certs/server.key # OpenVPN 服务器密钥路径，This file should be kept secret dh /etc/openvpn/server/certs/dh.pem # Diffie-Hellman 算法密钥文件路径 tls-auth /etc/openvpn/server/certs/ta.key 0 # tls-auth key，参数0可以省略，如果不省略，那么客户端配置相应的参数该配成 1。如果省略，那么客户端不需要 tls-auth 配置 server 10.8.0.0 255.255.255.0 # 该网段为 OpenVPN 虚拟网卡网段，不要和内网网段冲突即可。OpenVPN 默认为 10.8.0.0/24 push \u0026#34;dhcp-option DNS 8.8.8.8\u0026#34; # DNS 服务器配置，可以根据需要指定其他 ns push \u0026#34;dhcp-option DNS 8.8.4.4\u0026#34; push \u0026#34;route 172.19.0.0 255.255.0.0\u0026#34; # 当客户端打开 OpenVPN 连接后，所有访问172.19.0.0/24网段的流量都会被代理转发 #push \u0026#34;redirect-gateway def1\u0026#34; # 客户端所有流量都通过 OpenVPN 转发，类似于代理开全局 compress lzo #duplicate-cn # 允许一个用户多个终端连接 #max-clients 1 keepalive 10 120 comp-lzo persist-key persist-tun user openvpn # OpenVPN 进程启动用户，openvpn 用户在安装完 openvpn 后就自动生成了 group openvpn log /var/log/openvpn/server.log # 指定 log 文件位置 log-append /var/log/openvpn/server.log status /var/log/openvpn/status.log verb 3 explicit-exit-notify 1   2.8、清理所有防火墙规则 1  ➜ iptables -F   2.9、添加 SNAT 将OpenVPN的网络流量转发到公网\n1 2 3 4 5 6 7 8 9  #➜ iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE ➜ iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -p tcp -m multiport --dports 22,3306,4006,7777,6379,9100,9200,15672,28018 -j MASQUERADE ➜ iptables-save \u0026gt; /etc/sysconfig/iptables # iptables 规则持久化保存 # 将iptables规则设置为开机自动导入 ➜ vim /etc/rc.local iptables -F -t nat iptables -F iptables-restore \u0026lt; /etc/sysconfig/iptables   2.10、Linux 服务器启用核心转发 1 2 3 4  # 启用核心转发 ➜ echo net.ipv4.ip_forward = 1 \u0026gt;\u0026gt; /etc/sysctl.conf # 刷新内核 ➜ sysctl -p   三、启动 OpenVPN 1  ➜ systemctl start openvpn@server   四、连接 OpenVPN 以上过程已经将 OpenVPN 服务端搭建好了，现在我们需要使用客户端工具以及用户证书连接 OpenVPN服务端进行流量代理。\n在Mac下推荐使用 Tunnelblick，这是一个开源、免费的Mac版 OpenVPN客户端软件\n下载地址：https://tunnelblick.net/downloads.html\nWindows下使用官方提供的客户端工具即可\n下载地址：https://openvpn.net/community-downloads/\n4.1、增加一个用户 接下来在服务端创建一个OpenVPN用户：其实创建用户的过程就是通过服务端CA证书自签客户端证书的过程，然后将其他的证书文件、key、.ovpn(客户端配置文件)打包到一起供客户端使用。\n由于创建一个用户的过程比较繁琐，所以在此将整个过程写成了一个脚本，脚本通过修改模板文件生成新的ovpn文件，以及一系列用户相关证书后打成压缩包。\n4.1.1、ovpn模板文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ➜ cat sample.ovpn client proto udp dev tun remote [换成你的公网地址，即OpenVPN服务端所在地址] 57678 ca ca.crt cert admin.crt key admin.key tls-auth ta.key 1 remote-cert-tls server persist-tun persist-key comp-lzo verb 3 mute-replay-warnings   4.1.2、ovpn_user.sh 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  ➜ vim ovpn_user.sh # ! /bin/bash set -e OVPN_USER_KEYS_DIR=/etc/openvpn/client/keys EASY_WorkDir=/etc/openvpn/easy-rsa/3 PKI_DIR=$EASY_WorkDir/pki for user in \u0026#34;$@\u0026#34; do if [ -d \u0026#34;$OVPN_USER_KEYS_DIR/$user\u0026#34; ]; then rm -rf $OVPN_USER_KEYS_DIR/$user rm -rf $PKI_DIR/reqs/$user.req sed -i \u0026#39;/\u0026#39;\u0026#34;$user\u0026#34;\u0026#39;/d\u0026#39; $PKI_DIR/index.txt fi cd $EASY_WorkDir # 生成客户端 ssl 证书文件 ./easyrsa build-client-full $user # 整理下生成的文件 mkdir -p $OVPN_USER_KEYS_DIR/$user cp $PKI_DIR/ca.crt $OVPN_USER_KEYS_DIR/$user/ # CA 根证书 cp $PKI_DIR/issued/$user.crt $OVPN_USER_KEYS_DIR/$user/ # 客户端证书 cp $PKI_DIR/private/$user.key $OVPN_USER_KEYS_DIR/$user/ # 客户端证书密钥 cp /etc/openvpn/server/certs/ta.key $OVPN_USER_KEYS_DIR/$user/ta.key # auth-tls 文件 cp /etc/openvpn/client/sample.ovpn $OVPN_USER_KEYS_DIR/$user/$user.ovpn # 客户端配置文件 # 替换模板文件中的用户 sed -i \u0026#39;s/admin/\u0026#39;\u0026#34;$user\u0026#34;\u0026#39;/g\u0026#39; $OVPN_USER_KEYS_DIR/$user/$user.ovpn # 生成压缩包 cd $OVPN_USER_KEYS_DIR zip -r $user.zip $user # 拷贝压缩包至用户目录以下载 cp $user.zip /home/miaocunfa chown miaocunfa:miaocunfa /home/miaocunfa/$user.zip done exit 0   4.1.3、脚本使用语法 1  ➜ ./ovpn_user.sh \u0026lt;username\u0026gt;   4.1.4、生成压缩包 使用后在/etc/openvpn/client/keys文件夹下生成一个以username命名的zip文件，将此压缩包下载使用。\n1 2 3 4 5 6 7  # 压缩包中存在下列文件 . ├── ca.crt ├── username.crt ├── username.key ├── username.ovpn └── ta.key   4.1.5、使用客户端 当我们在windows上使用OpenVPN GUI时，此客户端需要默认安装，我们需要将刚才下载的压缩包中的所有文件拷贝至C:\\Program Files\\OpenVPN\\config中，然后即可使用客户端连接OpenVPN服务端了。\n4.2、删除一个用户 上面我们知道了如何添加一个用户，那么如果公司员工离职了或者其他原因，想删除对应用户 OpenVPN 的使用权，该如何操作呢？其实很简单，OpenVPN 的客户端和服务端的认证主要通过 SSL 证书进行双向认证，所以只要吊销对应用户的 SSL 证书即可。\n4.2.1、吊销用户证书，假设要吊销的用户名为 username 1 2 3 4 5 6 7 8 9  ➜ cd /etc/openvpn/easy-rsa/3/ ➜ ./easyrsa revoke username Revocation was successful. You must run gen-crl and upload a CRL to your # 吊销证书后必须执行gen-crl生成crl文件 infrastructure in order to prevent the revoked cert from being accepted. # 每次执行revoke，都要重新生成crl.pem文件 ➜ ./easyrsa gen-crl An updated CRL has been created. CRL file: /etc/openvpn/easy-rsa/3/pki/crl.pem # CRL文件路径   4.2.2、编辑 OpenVPN 服务端配置 server.conf 添加如下配置 1 2 3  ➜ vim server.conf # 添加 crl文件 crl-verify /etc/openvpn/easy-rsa/3/pki/crl.pem   4.2.3、重启 OpenVPN 服务端使其生效 1  ➜ systemctl start openvpn@server   4.2.4、一键删除用户 为了方便，也将上面步骤整理成了一个脚本 del_ovpn_user.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  ➜ vim del_ovpn_user.sh # ! /bin/bash set -e OVPN_USER_KEYS_DIR=/etc/openvpn/client/keys EASY_WorkDir=/etc/openvpn/easy-rsa/3 for user in \u0026#34;$@\u0026#34; do cd $EASY_WorkDir echo -e \u0026#39;yes\\n\u0026#39; | ./easyrsa revoke $user ./easyrsa gen-crl # 吊销掉证书后清理客户端相关文件 if [ -d \u0026#34;$OVPN_USER_KEYS_DIR/$user\u0026#34; ]; then rm -rf $OVPN_USER_KEYS_DIR/${user}* fi systemctl restart openvpn@server done exit 0   4.2.5、脚本使用语法 1  ➜ ./del_ovpn_user.sh \u0026lt;username\u0026gt;    参考列表：\n1、https://qhh.me/2019/06/16/Cenos7-%E4%B8%8B%E6%90%AD%E5%BB%BA-OpenVPN-%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/\n2、https://www.hi-linux.com/posts/43594.html\n ","description":"","id":11,"section":"ops","tags":["OpenVPN","内网穿透","公网穿透","加密隧道"],"title":"使用OpenVPN进行内网穿透与公网穿透","uri":"http://localhost:1818/ops/network/%E4%BD%BF%E7%94%A8openvpn%E8%BF%9B%E8%A1%8C%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E4%B8%8E%E5%85%AC%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"content":"一、环境准备 1.1、下载二进制源码包 1  wget http://apache.mirrors.hoobly.com/cassandra/3.11.5/apache-cassandra-3.11.5-bin.tar.gz   1.2、节点准备 1 2 3 4 5 6 7 8 9 10 11 12  # 准备三台节点 192.168.100.226 192.168.100.227 192.168.100.228 # ansible配置 # 因为是测试环境，这里就直接配置密码，不去麻烦的配置免密验证了。 [root@master ~]# cat /etc/ansible/hosts [casd] 192.168.100.226 ansible_ssh_user=\u0026#39;root\u0026#39; ansible_ssh_pass=\u0026#39;test123\u0026#39; 192.168.100.227 ansible_ssh_user=\u0026#39;root\u0026#39; ansible_ssh_pass=\u0026#39;test123\u0026#39; 192.168.100.228 ansible_ssh_user=\u0026#39;root\u0026#39; ansible_ssh_pass=\u0026#39;test123\u0026#39;   1.3、创建 Cassandra 用户 1 2 3 4 5 6 7 8 9 10 11  # 创建用户 ansible casd -m user -a \u0026#34;name=cassandra state=present\u0026#34; # 修改密码 ansible casd -m shell -a \u0026#34;echo cassandra | passwd --stdin cassandra\u0026#34; # 将cassandra二进制包拷贝到部署节点上。 ansible casd -m copy -a \u0026#34;src=apache-cassandra-3.11.5.tar.gz dest=/home/cassandra/apache-cassandra-3.11.5.tar.gz\u0026#34; # 解压源码包 ansible casd -m shell -a \u0026#34;cd /home/cassandra/; tar -zxvf apache-cassandra-3.11.5.tar.gz\u0026#34;   1.4、Java 环境准备 1 2 3 4 5 6 7 8 9 10 11 12  # 拷贝jdk至部署节点 ansible casd -m copy -a \u0026#34;src=java-1.8.0-amazon-corretto-devel-1.8.0_212.b04-2.x86_64.rpm dest=/root\u0026#34; # 安装jdk ansible casd -m shell -a \u0026#34;yum install -y java-1.8.0-amazon-corretto-devel-1.8.0_212.b04-2.x86_64.rpm\u0026#34; # 验证jdk ``` bash [root@localhost ~]# java -version openjdk version \u0026#34;1.8.0_212\u0026#34; OpenJDK Runtime Environment Corretto-8.212.04.2 (build 1.8.0_212-b04) OpenJDK 64-Bit Server VM Corretto-8.212.04.2 (build 25.212-b04, mixed mode)   1.5、配置用户环境变量 1 2 3 4 5 6 7 8 9 10 11 12  # 切换用户 [root@localhost ~]# su - cassandra  Last login: Fri Dec 6 04:27:53 EST 2019 on pts/1 # 配置环境变量 [cassandra@localhost ~]$ vi .bash_profile export CASSANDRA_HOME=/home/cassandra/apache-cassandra-3.11.5 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-amazon-corretto export PATH=$JAVA_HOME/bin:$CASSANDRA_HOME/bin:$PATH # 加载环境变量 [cassandra@localhost ~]$ source .bash_profile   二、部署 Cassandra 2.1、配置文件 修改配置文件 /home/cassandra/apache-cassandra-3.11.5/conf/cassandra.yaml\n1 2 3 4 5 6 7 8 9 10 11 12  cluster_name:\u0026#39;test\u0026#39;data_file_directories:- /home/cassandra/apache-cassandra-3.11.5/datacommitlog_directory:/home/cassandra/apache-cassandra-3.11.5/data/commitlogsaved_caches_directory:/home/cassandra/apache-cassandra-3.11.5/data/saved_cachesseed_provider:- class_name:org.apache.cassandra.locator.SimpleSeedProviderparameters:- seeds:\u0026#34;192.168.100.226\u0026#34;# 因子listen_address:192.168.100.226# 监听地址，不可以为127.0.0.1start_rpc:truerpc_address:192.168.100.226# rpc监听地址，不可以为127.0.0.1  2.2、各节点 各节点的 listen_address 和 rpc_address 需要按节点配置，且不能使用 localhost，因子 seeds 配置为第一个启动的节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  First Node -------------- seeds: \u0026#34;192.168.100.226\u0026#34; listen_address: 192.168.100.226 rpc_address: 192.168.100.226 Second Node --------------- seeds: \u0026#34;192.168.100.226\u0026#34; listen_address: 192.168.100.227 rpc_address: 192.168.100.227 Third Node --------------- seeds: \u0026#34;192.168.100.226\u0026#34; listen_address: 192.168.100.228 rpc_address: 192.168.100.228   三、启动 Cassandra 服务 3.1、启动服务 1 2 3 4 5 6  # 先启动226, 使用-f选项启动在前台 /home/cassandra/apache-cassandra-3.11.5/bin/cassandra # 再启动其余的节点 /home/cassandra/apache-cassandra-3.11.5/bin/cassandra /home/cassandra/apache-cassandra-3.11.5/bin/cassandra   3.验证服务 使用 nodetool status 验证服务\n1 2 3 4 5 6 7 8 9  [cassandra@localhost ~]$/home/cassandra/apache-cassandra-3.11.5/bin/nodetool status Datacenter: datacenter1 ======================= Status=Up/Down |/ State=Normal/Leaving/Joining/Moving -- Address Load Tokens Owns (effective) Host ID Rack UN 192.168.100.226 302.76 KiB 256 69.2% 723cb923-d19c-4dea-8124-c4503dab4d75 rack1 UN 192.168.100.227 295.05 KiB 256 66.3% 5bbeeb09-9bf4-4e45-a7a1-168e4f87186f rack1 UN 192.168.100.228 239.96 KiB 256 64.5% 78677dd0-797e-45b0-a34a-23842927af35 rack1   ","description":"","id":12,"section":"ops","tags":["Cassandra","NoSQL","数据库"],"title":"部署 Cassandra 集群","uri":"http://localhost:1818/ops/deploy/%E9%83%A8%E7%BD%B2cassandra%E9%9B%86%E7%BE%A4/"},{"content":"group模块是用来添加或者删除组\n首先使用ansible-doc来查看用法\n1 2 3 4 5 6 7 8 9 10 11 12  [root@note0 ansible]# ansible-doc -s group - name: Add or remove groups group: gid: # Optional `GID\u0026#39; to set for the group. local: # Forces the use of \u0026#34;local\u0026#34; command alternatives on platforms that implement it. This is useful in environments that use centralized authentication when you want to manipulate the local groups. (e.g. it uses `lgroupadd\u0026#39; instead of `groupadd\u0026#39;). This requires that these commands exist on the targeted host, otherwise it will be a fatal error. name: # (required) Name of the group to manage. non_unique: # This option allows to change the group ID to a non-unique value. Requires `gid\u0026#39;. Not supported on macOS or BusyBox distributions. state: # Whether the group should be present or not on the remote host. system: # If `yes\u0026#39;, indicates that the group created is a system group.   通过上面的参数列表我们可以了解到group模块有几个重要属性\nOPTIONS (= is mandatory):选项前面为=的为必填参数\n一、name = name\rName of the group to manage.\rtype: str\r要操作的group的组名，string类型，必填项\r1.1、示例 创建一个名字为test的组。\n1 2 3 4 5 6 7 8 9 10 11  [root@note0 ~]# ansible local -m group -a \u0026#34;name=test\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026lt;font color=\u0026#34;red\u0026#34;\u0026gt;\u0026#34;changed\u0026#34;: true,\u0026lt;/font\u0026gt;#可以看到changed状态为true，代表已经在主机添加组成功。 \u0026#34;gid\u0026#34;: 1000, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false }   查看主机/etc/group文件验证\n[root@note1 ~]# cat /etc/group\rtest❌1000:\r二、state - state\rWhether the group should be present or not on the remote host.\r(Choices: absent, present)[Default: present]\rtype: str\rstate用于指定用户组在远程主机上是否被更改或删除，string类型。\r有两个选项：absent，present。默认值为present，absent为删除组。\r2.1、示例 我们来删除一下刚才创建的组。\n[root@note0 ~]# ansible local -m group -a \u0026quot;name=test state=absent\u0026quot;\r176.16.128.1 | CHANGED =\u0026gt; {\r\u0026quot;ansible_facts\u0026quot;: {\r\u0026quot;discovered_interpreter_python\u0026quot;: \u0026quot;/usr/bin/python\u0026quot;\r}, \u0026quot;changed\u0026quot;: true, \u0026quot;name\u0026quot;: \u0026quot;test\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;absent\u0026quot;\r}\r三、gid - gid\rOptional `GID' to set for the group.\r[Default: (null)]\rtype: int\rgid用于设定用户组gid，int类型，默认值为空\r3.1、示例 创建一个gid为1005，名字为test的组。\n[root@note0 ~]# ansible local -m group -a \u0026quot;name=test gid=1005 state=present\u0026quot;\r176.16.128.1 | CHANGED =\u0026gt; {\r\u0026quot;ansible_facts\u0026quot;: {\r\u0026quot;discovered_interpreter_python\u0026quot;: \u0026quot;/usr/bin/python\u0026quot;\r}, \u0026quot;changed\u0026quot;: true, \u0026quot;gid\u0026quot;: 1005, \u0026quot;name\u0026quot;: \u0026quot;test\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;present\u0026quot;, \u0026quot;system\u0026quot;: false\r}\r查看主机/etc/group文件，我们可以看到新创建的组gid为1005。\n[root@note1 ~]# cat /etc/group\rtest❌1005:\r四、system - system\rIf `yes', indicates that the group created is a system group.\r[Default: False]\rtype: bool\rsystem用于指定创建的用户组是否为系统组，布尔类型，可用选项false，true，默认为false\r4.1、示例 创建一个名字为test的系统组。\n1 2 3 4 5 6 7 8 9 10 11  [root@note0 ~]# ansible local -m group -a \u0026#34;name=test state=present system=true\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;gid\u0026#34;: 994, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: true }   查看主机/etc/group文件验证\n1 2  [root@note1 ~]# cat /etc/group test❌994:   可以看到test组的gid为994，gid小于1000为系统组。\n","description":"","id":13,"section":"ops","tags":["ansible","自动化运维","DevOps"],"title":"运维自动化神器 Ansible之Group(三)","uri":"http://localhost:1818/ops/devops/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A5%9E%E5%99%A8ansible%E4%B9%8Bgroup/"},{"content":"一、概述  ping模块 用来检测主机连通性。\nping模块返回值\nRETURN VALUES:\rping:\rdescription: value provided with the data parameter\rreturned: success\rtype: str\rsample: pong\r因为ping模块只是用来检测主机连通性，所以使用ping模块时是不需要-a指定参数的。\n二、示例 1 2 3 4 5 6 7 8 9 10  [root@master01 ~]# ansible 172.31.194.117 -m ping /usr/lib/python2.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (2.2.1) doesn\u0026#39;t match a supported version! RequestsDependencyWarning) 172.31.194.117 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; }   ping返回pong这就说明主机是可以连接的，可以进行后续的其他操作了。\n","description":"","id":14,"section":"ops","tags":["ansible","自动化运维","DevOps"],"title":"运维自动化神器 Ansible之Ping(二)","uri":"http://localhost:1818/ops/devops/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A5%9E%E5%99%A8ansible%E4%B9%8Bping/"},{"content":"一、概述  user模块 可管理远程主机上的 用户，比如创建用户、修改用户、删除用户、为用户创建密钥对等操作。\n二、参数介绍   name： 用于指定操作的 user，必须项。 uid： 用于指定 user 的 UID，默认为空。 non_unique： 与uid参数一起使用，允许改变UID为非唯一值。 group： 参数用于指定用户 主组。默认值为空，为空时创建的用户组名跟用户名一致。 groups： 参数用于指定用户属组，可以在创建用户时指定用户属组，也可以管理已经存在的用户属组。 append： 跟groups参数一起使用管理用户属组，默认为false，如果 append='yes' ，则从groups参数中增加用户的属组；如果 append='no' ，则用户属组只设置为groups中的组，移除其他所有属组。 state： 参数用于指定用户是否存在于远程主机中。可选值有 present、absent，默认值为 present。 remove： 参数在 state=absent 时使用，等价于 userdel --remove 布尔类型，默认值为 false。 force： 参数在 state=absent 时使用，等价于 userdel --force，布尔类型，默认值为 false。 home： 参数用于指定用户home目录，值为路径 create_home： 在用户创建时或home目录不存在时为用户创建home目录，布尔类型，默认值为 true move_home： 如果设置为yes，结合home= 使用，临时迁移用户家目录到特定目录 comment： 参数用于指定用户注释信息 shell： 参数用于指定用户默认shell system： 参数用于指定用户是否是系统用户 expires： 参数用于指定用户过期时间，相当于设置 /etc/shadow 文件中的的 第8列 passwd： 参数用于指定用户密码，但是这个密码不能是明文密码，而是一个对明文密码加密后的字符串，默认为空 password_lock： 参数用于锁定指定用户，布尔类型，默认为空 update_password： 参数可选值有always 和 on_create，默认为always 。\n当设置为always时，password参数的值与 /etc/shadow 中密码字符串不一致时更新用户的密码；\n当设置为on_create时，password参数的值与 /etc/shadow 中密码字符串不一致时也不会更新用户的密码，但如果是新创建的用户，则此参数即使为on_create，也会更新用户密码。 generate_ssh_key： 参数用于指定是否生成ssh密钥对，布尔类型，默认为false。当设置为yes时，为用户生成 ssh 密钥对，默认在 ~/.ssh 目录中生成名为 id_rsa私钥 和 id_rsa.pub公钥，如果同名密钥已经存在，则不做任何操作。 sssh_key_bits： 当 generate_ssh_key=yes 时，指定生成的ssh key加密位数。 ssh_key_file： 当 generate_ssh_key=yes 时，使用此参数指定ssh私钥的路径及名称，会在同路径下生成以私钥名开头以 .pub 结尾对应公钥。 ssh_key_comment： 当 generate_ssh_key=yes 时，在创建证书时，使用此参数设置公钥中的注释信息。如果同名密钥已经存在，则不做任何操作。当不指定此参数时，默认注释信息为\u0026quot;ansible-generated on $hostname”。 ssh_key_passphrase： 当 generate_ssh_key=yes 时，在创建证书时，使用此参数设置私钥密码。如果同名密钥已经存在，则不做任何操作。 ssh_key_type： 当 generate_ssh_key=yes 时，在创建证书时，使用此参数指定密钥对的类型。默认值为 rsa，如果同名密钥已经存在，则不做任何操作。  三、参数详解  下列英文文档部分来自于 ansible-doc，参数的修饰符号为 \u0026quot;=\u0026quot; 或 \u0026quot;-\u0026quot;\nOPTIONS (= is mandatory)：= 号开始的为必须给出的参数\n3.1 name name： 用于指定操作的 user，必须项\n1 2 3 4  = name Name of the user to create, remove or modify. (Aliases: user) type: str    3.1.1 示例 使用 ansible 在 note1 节点上增加 test 用户\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=test\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1000, \u0026#34;home\u0026#34;: \u0026#34;/home/test\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1000 } [root@note0 ~]#    验证 用户 是否 添加 成功，查看 note1 节点下的 /etc/passwd 文件\n1 2  [root@note1 ~]# tail -1 /etc/passwd test❌1000:1000::/home/test:/bin/bash    3.2 uid uid： 用于指定 user 的 UID，默认为空\n1 2 3 4  - uid Optionally sets the `UID\u0026#39; of the user. [Default: (null)] type: int   3.2.1 示例 使用 ansible 在 note1 节点上增加 testuid 用户\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuid uid=2000\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 2000, \u0026#34;home\u0026#34;: \u0026#34;/home/testuid\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testuid\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 2000 } [root@note0 ~]#    验证 用户 是否 添加 成功，查看 note1 节点下的 /etc/passwd 文件\n1 2  [root@note1 ~]# tail -1 /etc/passwd testuid❌2000:2000::/home/testuid:/bin/bash   3.3 state state： 参数用于指定用户是否存在于远程主机中。\n可选值有 present、absent：\n默认值为 present，表示用户存在，相当于在远程主机创建用户；\n当设置为 absent 时表示用户不存在，相当于在远程主机删除用户。\n1 2 3 4  - state Whether the account should exist or not, taking action if the state is different from what is stated. (Choices: absent, present)[Default: present] type: str   3.3.1 示例 使用 ansible 在 note1 节点上删除 test 用户\n1 2 3 4 5 6 7 8 9 10 11 12  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=test state=absent\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;force\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;remove\u0026#34;: false, \u0026#34;state\u0026#34;: \u0026#34;absent\u0026#34; } [root@note0 ~]#    验证 用户 是否 删除 成功，查看 note1 节点下是否存在 test 用户\n1 2  [root@note1 ~]# id test id: test: no such user   3.4 remove remove： 参数在 state=absent 时使用，等价于 userdel --remove 布尔类型，默认值为 false。\n1 2 3 4 5  - remove This only affects `state=absent\u0026#39;, it attempts to remove directories associated with the user. The behavior is the same as `userdel --remove\u0026#39;, check the man page for details and support. [Default: False] type: bool   3.4.1 示例1 在 示例3.3.1 中我们已经使用 ansible 在 note1 节点上删除了 test 用户，现在让我们查看test用户home目录是否存在。\n1 2 3 4 5 6 7  [root@note1 ~]# cd /home #查看home目录 [root@note1 home]# ll 总用量 0 drwx------ 2 1000 1000 59 7月 9 16:41 test drwx------ 2 testuid testuid 59 7月 9 17:01 testuid [root@note1 home]#   我们可以看到，通过state=absent删除的用户home目录还存在，下面我们来演示一下彻底删除一个用户。\n3.4.2 示例2 使用 ansible 在 note1 节点上删除 testuid 用户\n1 2 3 4 5 6 7 8 9 10 11 12  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuid state=absent remove=yes\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;force\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;testuid\u0026#34;, \u0026#34;remove\u0026#34;: true, \u0026#34;state\u0026#34;: \u0026#34;absent\u0026#34; } [root@note0 ~]#    下面我们来验证一下，用户及home目录是否彻底删除\n1 2 3 4 5 6 7 8  #查看testuid用户是否存在 [root@note1 home]# id testuid id: testuid: no such user #查看home目录 [root@note1 home]# ll 总用量 0 drwx------ 2 1000 1000 59 7月 9 16:41 test [root@note1 home]#   3.5 group group： 参数用于指定用户 主组。默认值为空，创建的用户组名跟用户名一致。\n1 2 3 4  - group Optionally sets the user\u0026#39;s primary group (takes a group name). [Default: (null)] type: str   3.5.1 示例 使用 ansible 在 note1 节点上 创建test 用户，并指定主组为 testgrp\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  #首先创建使用ansible创建testgrp组 [root@note0 ~]# ansible note1 -m group -a \u0026#34;name=testgrp state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;gid\u0026#34;: 1000, \u0026#34;name\u0026#34;: \u0026#34;testgrp\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false } #使用ansible创建test用户 [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=test group=testgrp state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1000, \u0026#34;home\u0026#34;: \u0026#34;/home/test\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1000 } [root@note0 ~]#    验证 用户 是否 创建 成功\n1 2  [root@note1 home]# id test uid=1000(test) gid=1000(testgrp) 组=1000(testgrp)   3.6 groups、append groups： 参数用于指定用户属组，可以在创建用户时指定用户属组，也可以管理已经存在的用户属组。\ngroups为列表类型，多个参数以逗号分隔，例如 groups='grp,mygrp'；默认值 为 空 ，也可以设置空字符串 groups=''，groups=`null` ，groups=`~` ，将用户从其他属组 移除。\nappend： 跟groups参数一起使用管理用户属组。布尔类型，默认为false，如果 append='yes' ，则从groups参数中增加用户的属组；如果 append='no' ，则用户属组只设置为groups中的组，移除其他所有属组。\n1 2 3 4 5 6 7 8 9 10 11 12  - groups List of groups user will be added to. When set to an empty string `\u0026#39;\u0026#39;\u0026#39;, `null\u0026#39;, or `~\u0026#39;, the user is removed from all groups except the primary group. (`~\u0026#39; means `null\u0026#39; in YAML) Before Ansible 2.3, the only input format allowed was a comma separated string. [Default: (null)] type: list - append If `yes\u0026#39;, add the user to the groups specified in `groups\u0026#39;. If `no\u0026#39;, user will only be added to the groups specified in `groups\u0026#39;, removing them from all other groups. [Default: False] type: bool   3.6.1 示例1-创建用户时指定属组 先使用 ansible 在 note1 节点上创建 mygrp1，mygrp2，mygrp3 测试组\n1 2 3 4 5 6 7 8 9 10  #首先创建使用创建测试组 [root@note0 ~]# ansible note1 -m group -a \u0026#34;name=mygrp1 gid=2001 state=present\u0026#34; [root@note0 ~]# ansible note1 -m group -a \u0026#34;name=mygrp2 gid=2002 state=present\u0026#34; [root@note0 ~]# ansible note1 -m group -a \u0026#34;name=mygrp3 gid=2003 state=present\u0026#34; #测试组创建成功 [root@note1 home]# cat /etc/group mygrp1❌2001: mygrp2❌2002: mygrp3❌2003:    创建用户 testuser，并指定属组为 mygrp1 mygrp2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuser groups=mygrp1,mygrp2 state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1001, \u0026#34;groups\u0026#34;: \u0026#34;mygrp1,mygrp2\u0026#34;, \u0026#34;home\u0026#34;: \u0026#34;/home/testuser\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1001 } [root@note0 ~]#    验证用户 testuser的属组为mygrp1，mygrp2\n1 2  [root@note1 home]# id testuser uid=1001(testuser) gid=1001(testuser) 组=1001(testuser),2001(mygrp1),2002(mygrp2)   3.6.2 示例2-已创建用户增加属组 将testuser的属组变更为mygrp1，mygrp2，mygrp3\n3.6.2.1 不使用append，使用groups指明用户的所有属组即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuser groups=\u0026#39;mygrp1,mygrp2,mygrp3\u0026#39; state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;append\u0026#34;: false, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;group\u0026#34;: 1001, \u0026#34;groups\u0026#34;: \u0026#34;mygrp1,mygrp2,mygrp3\u0026#34;, \u0026#34;home\u0026#34;: \u0026#34;/home/testuser\u0026#34;, \u0026#34;move_home\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;uid\u0026#34;: 1001 } [root@note0 ~]#    验证用户testuser的属组是否为mygrp1，mygrp2，mygrp3\n1 2  [root@note1 home]# id testuser uid=1001(testuser) gid=1001(testuser) 组=1001(testuser),2001(mygrp1),2002(mygrp2),2003(mygrp3)   3.6.2.2 使用append属性 先将testuser用户属组还原为mygrp1，mygrp2\n再增加属组mygrp3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #使用append=yes时，只将要添加的属组填入groups参数中即可。 [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuser groups=\u0026#39;mygrp3\u0026#39; append=yes state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;append\u0026#34;: true, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;group\u0026#34;: 1001, \u0026#34;groups\u0026#34;: \u0026#34;mygrp3\u0026#34;, \u0026#34;home\u0026#34;: \u0026#34;/home/testuser\u0026#34;, \u0026#34;move_home\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;uid\u0026#34;: 1001 } [root@note0 ~]#    验证用户testuser的属组是否为mygrp1，mygrp2，mygrp3\n1 2  [root@note1 home]# id testuser uid=1001(testuser) gid=1001(testuser) 组=1001(testuser),2001(mygrp1),2002(mygrp2),2003(mygrp3)   3.6.3 示例3-已创建用户移除属组 将testuser的属组变更为mygrp1\n3.6.3.1 不使用append，使用groups指明用户的所有属组即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuser groups=\u0026#39;mygrp1\u0026#39; state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;append\u0026#34;: false, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;group\u0026#34;: 1001, \u0026#34;groups\u0026#34;: \u0026#34;mygrp1\u0026#34;, \u0026#34;home\u0026#34;: \u0026#34;/home/testuser\u0026#34;, \u0026#34;move_home\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;uid\u0026#34;: 1001 } [root@note0 ~]#    验证用户testuser的属组是否为mygrp1\n1 2  [root@note1 home]# id testuser uid=1001(testuser) gid=1001(testuser) 组=1001(testuser),2001(mygrp1)   3.6.3.2 使用append属性 先将testuser用户属组还原为mygrp1，mygrp2，mygrp3\n再变更用户testuser属组为mygrp3\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #使用append=no时，用户的属组只设置为groups参数中的组 [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testuser groups=\u0026#39;mygrp1\u0026#39; append=\u0026#39;no\u0026#39; state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;append\u0026#34;: false, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;group\u0026#34;: 1001, \u0026#34;groups\u0026#34;: \u0026#34;mygrp1\u0026#34;, \u0026#34;home\u0026#34;: \u0026#34;/home/testuser\u0026#34;, \u0026#34;move_home\u0026#34;: false, \u0026#34;name\u0026#34;: \u0026#34;testuser\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;uid\u0026#34;: 1001 } [root@note0 ~]#    验证用户testuser的属组是否为mygrp1\n1 2  [root@note1 home]# id testuser uid=1001(testuser) gid=1001(testuser) 组=1001(testuser),2001(mygrp1)   3.7 passwd passwd： 参数用于指定用户密码，但是这个密码不能是明文密码，而是一个对明文密码加密后的字符串，相当于 /etc/shadow 文件中的密码字段，是一个对明文密码进行哈希后的字符串，可以使用命令生成明文密码对应的加密字符串。\n1 2 3 4 5 6 7 8  - password Optionally set the user\u0026#39;s password to this crypted value. On macOS systems, this value has to be cleartext. Beware of security issues. To create a disabled account on Linux systems, set this to `\u0026#39;!\u0026#39;\u0026#39; or `\u0026#39;*\u0026#39;\u0026#39;. See https://docs.ansible.com/ansible/faq.html#how-do-i-generate-crypted-passwords-for-the-user-module for details on various ways to generate these password values. [Default: (null)] type: str    要生成md5算法的密码，使用openssl即可。\n1 2  openssl passwd -1 \u0026#39;123456\u0026#39; openssl passwd -1 -salt \u0026#39;abcdefg\u0026#39; \u0026#39;123456\u0026#39;    但 openssl passwd 不支持生成sha-256和sha-512算法的密码。使用python命令生成sha-512算法\n1  python -c \u0026#39;import crypt,getpass;pw=\u0026#34;123456\u0026#34;;print(crypt.crypt(pw))\u0026#39;    现在就方便多了，直接将结果赋值给变量即可。\n1 2 3  [root@note0 ~]# a=$(python -c \u0026#39;import crypt,getpass;pw=\u0026#34;123456\u0026#34;;print(crypt.crypt(pw))\u0026#39;) [root@note0 ~]# echo $a $6$uKhnBg5A4/jC8KaU$scXof3ZwtYWl/6ckD4GFOpsQa8eDu6RDbHdlFcRLd/2cDv5xYe8hzw5ekYCV5L2gLBBSfZ.Uc166nz6TLchlp.    例如，ansible创建用户并指定密码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  [root@note0 ~]# a=$(python -c \u0026#39;import crypt,getpass;pw=\u0026#34;123456\u0026#34;;print(crypt.crypt(pw))\u0026#39;) [root@note0 ~]# ansible note1 -m user -a \u0026#39;name=testpass password=\u0026#34;$a\u0026#34; update_password=always\u0026#39; [WARNING]: The input password appears not to have been hashed. The \u0026#39;password\u0026#39; argument must be encrypted for this module to work properly. 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1005, \u0026#34;home\u0026#34;: \u0026#34;/home/testpass\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testpass\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;NOT_LOGGING_PASSWORD\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1005 } [root@note0 ~]#    登录验证\n1 2 3 4 5 6  [root@note0 ~]# ssh testpass@note1 testpass@note1\u0026#39;s password: Last login: Thu Jul 11 00:12:57 2019 from note0 [testpass@note1 ~]$ who am i testpass pts/1 2019-07-11 00:13 (note0) [testpass@note1 ~]$   3.8 expires expires： 参数用于指定用户过期时间，相当于设置 /etc/shadow 文件中的的 第8列 ，比如，你想要设置用户的过期日期为2019年07月10日，那么你首先要获取2019年07月10日的 unix 时间戳，使用命令 date -d 20190710 +%s 获取到的时间戳为1562688000，所以，当设置 expires=1562688000 时，表示用户的过期时间为2019年07月10日0点0分，设置成功后，查看远程主机的 /etc/shadow 文件，对应用户的第8列的值将变成18086（表示1970年1月1日到2019年07月10日的天数，unix 时间戳的值会自动转换为天数，我们不用手动的进行换算），当前ansible版本此参数支持在GNU/Linux, FreeBSD, and DragonFlyBSD 系统中使用。\n3.8.1 示例 设置一个过期时间为20190710的用户testexprie\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testexpire expires=1562688000 comment=\u0026#39;expires date is 20190710\u0026#39; state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;expires date is 20190710\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1003, \u0026#34;home\u0026#34;: \u0026#34;/home/testexpire\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testexpire\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1003 } [root@note0 ~]#    在note1上验证testexprie用户\n1 2  [root@note1 home]# cat /etc/shadow testexpire:!!:18086:0:99999:7::18086:   登录失败，提示账号过期\n[root@note0 ~]# ssh testexpire@note1\rtestexpire@note1's password: Your account has expired; please contact your system administrator\rConnection closed by 176.16.128.1\r3.9 home home： 参数用于指定用户home目录，值为路径\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  - home Optionally set the user\u0026#39;s home directory. [Default: (null)] type: path - create_home Unless set to `no\u0026#39;, a home directory will be made for the user when the account is created or if the home directory does not exist. Changed from `createhome\u0026#39; to `create_home\u0026#39; in Ansible 2.5. (Aliases: createhome)[Default: True] type: bool - move_home If set to `yes\u0026#39; when used with `home: \u0026#39;, attempt to move the user\u0026#39;s old home directory to the specified directory if it isn\u0026#39;t there already and the old home exists. [Default: False] type: bool   3.9.1 示例 [root@note0 ~]# ansible note1 -m user -a \u0026quot;name=testhome home=/home/testdir state=present\u0026quot;\r176.16.128.1 | CHANGED =\u0026gt; {\r\u0026quot;ansible_facts\u0026quot;: {\r\u0026quot;discovered_interpreter_python\u0026quot;: \u0026quot;/usr/bin/python\u0026quot;\r}, \u0026quot;changed\u0026quot;: true, \u0026quot;comment\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;create_home\u0026quot;: true, \u0026quot;group\u0026quot;: 1004, \u0026quot;home\u0026quot;: \u0026quot;/home/testdir\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;testhome\u0026quot;, \u0026quot;shell\u0026quot;: \u0026quot;/bin/bash\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;present\u0026quot;, \u0026quot;system\u0026quot;: false, \u0026quot;uid\u0026quot;: 1004\r}\r[root@note0 ~]#  验证testhome用户的home目录\n1 2 3 4 5 6 7 8  # 首先登录note1节点，su到testhome用户 [root@note1 ~]# su - testhome # cd 到主目录 [testhome@note1 ~]$ cd ~ # 执行pwd [testhome@note1 ~]$ pwd /home/testdir [testhome@note1 ~]$   3.10 move_home move_home： 如果设置为yes，结合home= 使用，临时迁移用户家目录到特定目录\n1 2 3 4 5  - move_home If set to `yes\u0026#39; when used with `home: \u0026#39;, attempt to move the user\u0026#39;s old home directory to the specified directory if it isn\u0026#39;t there already and the old home exists. [Default: False] type: bool   3.10.1 示例 首先创建testmove用户，然后在testmove用户home目录下创建test_move_home.txt文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  #创建testmove用户。 [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testmove state=present\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1006, \u0026#34;home\u0026#34;: \u0026#34;/home/testmove\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testmove\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1006 } #使用ansible的file模块在testmove用户home目录下创建test_move_home.txt文件 [root@note0 ~]# ansible note1 -m file -a \u0026#34;path=/home/testmove/test_move_home.txt state=touch\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;dest\u0026#34;: \u0026#34;/home/testmove/test_move_home.txt\u0026#34;, \u0026#34;gid\u0026#34;: 0, \u0026#34;group\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;0644\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;size\u0026#34;: 0, \u0026#34;state\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;uid\u0026#34;: 0 } #在note1节点上，查看/home/testmove下是否存在test_move_home.txt [root@note1 ~]# cd /home/testmove [root@note1 testmove]# ll 总用量 0 -rw-r--r-- 1 root root 0 7月 11 06:22 test_move_home.txt [root@note1 testmove]#   使用ansible的move_home参数迁移用户home目录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #迁移testmove用户的home目录至/tmp/testmove_new [root@note0 ~]# ansible note1 -m user -a \u0026#34;user=testmove move_home=yes home=/tmp/testmove_new/\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;append\u0026#34;: false, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;group\u0026#34;: 1006, \u0026#34;home\u0026#34;: \u0026#34;/tmp/testmove_new/\u0026#34;, \u0026#34;move_home\u0026#34;: true, \u0026#34;name\u0026#34;: \u0026#34;testmove\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;uid\u0026#34;: 1006 } [root@note0 ~]#   验证迁移的新home目录下是否存在test_move_home.txt文件\n1 2 3 4 5  [root@note1 testmove]# cd /tmp/testmove_new/ [root@note1 testmove_new]# ll 总用量 0 -rw-r--r-- 1 root root 0 7月 11 06:22 test_move_home.txt [root@note1 testmove_new]#   3.11 generate_ssh_key generate_ssh_key： 参数用于指定是否生成ssh密钥对，布尔类型，默认为false。当设置为yes时，为用户生成 ssh 密钥对，默认在 ~/.ssh 目录中生成名为 id_rsa私钥 和 id_rsa.pub公钥，如果同名密钥已经存在，则不做任何操作。\n1 2 3 4 5 6  - generate_ssh_key Whether to generate a SSH key for the user in question. This will *not* overwrite an existing SSH key unless used with `force=yes\u0026#39;. [Default: False] type: bool version_added: 0.9   3.11.1 示例 使用ansible创建testssh用户，并生成ssh_key。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  [root@note0 ~]# ansible note1 -m user -a \u0026#34;name=testssh state=present generate_ssh_key=yes\u0026#34; 176.16.128.1 | CHANGED =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: true, \u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;create_home\u0026#34;: true, \u0026#34;group\u0026#34;: 1007, \u0026#34;home\u0026#34;: \u0026#34;/home/testssh\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;testssh\u0026#34;, \u0026#34;shell\u0026#34;: \u0026#34;/bin/bash\u0026#34;, \u0026#34;ssh_fingerprint\u0026#34;: \u0026#34;2048 07:18:48:ea:f1:dc:95:22:75:fc:b5:5e:80:25:a7:1f ansible-generated on note1 (RSA)\u0026#34;, \u0026#34;ssh_key_file\u0026#34;: \u0026#34;/home/testssh/.ssh/id_rsa\u0026#34;, \u0026#34;ssh_public_key\u0026#34;: \u0026#34;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDIrQCOP11FK/s50vpOm/z+hXEmet+oEdWqGbyQD0JdN0AJrS/MzHZF3v+sjMf4SoDL7PafPYnFY4iVEtNOuBK8uvQgziVXVRxPs7h9Yy+ZdFw8qFjeiC74pKl+0Mqq49I9TD1GMbOQRd0K7nTycymCAX0MW5lQz7q44f3qa4+4y8C63xxi/4H9x3lJ+JsjDDIzKo4i69CnqU3Bn+0HzfxYi9j63HtcdLF8OwVfyF73lK6xd+vK68AaxRfPIOEj4KJXU3iMdiM5zVvMZgjEKyaGKPJD/uQl35MV2oazmFHTHWrKgA5AXwJEMKJYJzF6a8Z6SrmSnvxp6TpnMmbXAjev ansible-generated on note1\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;present\u0026#34;, \u0026#34;system\u0026#34;: false, \u0026#34;uid\u0026#34;: 1007 } [root@note0 ~]#   验证note1节点下的ssh_key文件\n1 2 3 4 5 6 7 8  [root@note1 ~]# cd /home/testssh/.ssh [root@note1 .ssh]# ll 总用量 8 -rw------- 1 testssh testssh 1679 7月 11 06:39 id_rsa -rw-r--r-- 1 testssh testssh 408 7月 11 06:39 id_rsa.pub [root@note1 .ssh]# cat id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDIrQCOP11FK/s50vpOm/z+hXEmet+oEdWqGbyQD0JdN0AJrS/MzHZF3v+sjMf4SoDL7PafPYnFY4iVEtNOuBK8uvQgziVXVRxPs7h9Yy+ZdFw8qFjeiC74pKl+0Mqq49I9TD1GMbOQRd0K7nTycymCAX0MW5lQz7q44f3qa4+4y8C63xxi/4H9x3lJ+JsjDDIzKo4i69CnqU3Bn+0HzfxYi9j63HtcdLF8OwVfyF73lK6xd+vK68AaxRfPIOEj4KJXU3iMdiM5zVvMZgjEKyaGKPJD/uQl35MV2oazmFHTHWrKgA5AXwJEMKJYJzF6a8Z6SrmSnvxp6TpnMmbXAjev ansible-generated on note1 [root@note1 .ssh]#    ansible的user模块常用参数就介绍到这里，不做过多赘述了。欢迎指点交流。\n","description":"","id":15,"section":"ops","tags":["ansible","自动化运维","DevOps"],"title":"运维自动化神器 Ansible之User(四)","uri":"http://localhost:1818/ops/devops/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A5%9E%E5%99%A8ansible%E4%B9%8Buser/"},{"content":"一、安装部署 1  yum install ansible   通过rpm -ql命令我们可以看到 ansible 有很多的子命令以及他们的安装位置。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  [root@master01 ~]# rpm -ql ansible | grep bin /usr/bin/ansible /usr/bin/ansible-2 /usr/bin/ansible-2.7 /usr/bin/ansible-config /usr/bin/ansible-connection /usr/bin/ansible-console /usr/bin/ansible-console-2 /usr/bin/ansible-console-2.7 /usr/bin/ansible-doc /usr/bin/ansible-doc-2 /usr/bin/ansible-doc-2.7 /usr/bin/ansible-galaxy /usr/bin/ansible-galaxy-2 /usr/bin/ansible-galaxy-2.7 /usr/bin/ansible-inventory /usr/bin/ansible-playbook /usr/bin/ansible-playbook-2 /usr/bin/ansible-playbook-2.7 /usr/bin/ansible-pull /usr/bin/ansible-pull-2 /usr/bin/ansible-pull-2.7 /usr/bin/ansible-vault /usr/bin/ansible-vault-2 /usr/bin/ansible-vault-2.7   二、配置文件 ansible配置文件默认安装在/etc/ansible下\n1 2 3 4 5 6 7  [root@master01 ansible]# pwd /etc/ansible [root@master01 ansible]# ll total 28 -rw-r--r-- 1 root root 19980 Sep 14 04:00 ansible.cfg -rw-r--r-- 1 root root 1016 Sep 14 04:00 hosts drwxr-xr-x 2 root root 4096 Sep 14 04:00 roles   2.1、hosts配置文件解析 hosts文件是我们使用ansible操作的主机模板文件。\n# 可以如以下模块这样配置域名或者主机IP地址\rgreen.example.com\rblue.example.com\r192.168.100.1\r192.168.100.10\r# 也可以设置分组, 使用ansible的时候指定操作的组。\r[webservers]\ralpha.example.org\rbeta.example.org\r192.168.1.100\r192.168.1.110\r# 如果多个主机遵循一个命名规则，也可以如下配置。\rwww[001:006].example.com\r2.2、配置ansible.cfg文件 因为我们不配置ssh免密验证，所以要修改一下ansible.cfg文件。\n1 2  [root@master01 ansible]# vi /etc/ansible/ansible.cfg host_key_checking = False   2.3、配置hosts文件 如果主机间还没有配置ssh免密验证，需要在配置文件中配置用户名、密码。\n[master]\r172.31.194.114 ansible_ssh_user='root' ansible_ssh_pass='miao123!'\r172.31.194.115 ansible_ssh_user='root' ansible_ssh_pass='miao123!'\r172.31.194.116 ansible_ssh_user='root' ansible_ssh_pass='miao123!'\r[node]\r172.31.194.117 ansible_ssh_user='root' ansible_ssh_pass='miao123!'\r三、ansible使用语法 这里只列出一些重要的ansible语法及参数。\n1 2 3 4 5 6 7 8 9 10  [root@master01 ansible]# ansible --help Usage: ansible \u0026lt;host-pattern\u0026gt; [options] # 我们可以看到ansible命令后需要指定主机模板文件，默认hosts文件不需要指定。 Options: -C, --check # 使用 -C 或 --check 来干跑一遍不执行任何修改（检查语法错误及查看目标达成状态）  -f FORKS, --forks=FORKS # 指定一次运行几台主机的任务，默认是5 -m MODULE_NAME, --module-name=MODULE_NAME # 执行的模块名称  -a MODULE_ARGS, --args=MODULE_ARGS # 使用 -a 或 -args 来指定模块参数 -h, --help # 获得帮助 --list-hosts # 列出有哪些主机执行操作    四、连通性调试 4.1、先通过\u0026ndash;list-host查看hosts文件配置是否有误。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # 列出所有主机 [root@master01 ansible]# ansible all --list-host hosts (4): 172.31.194.117 172.31.194.114 172.31.194.115 172.31.194.116 # 列出所有master主机 [root@master01 ansible]# ansible master --list-host hosts (3): 172.31.194.114 172.31.194.115 172.31.194.116 # 列出所有node主机 [root@master01 ansible]# ansible node --list-host hosts (1): 172.31.194.117   4.2、ping模块测试主机连通性 使用 ping 模块时，不用再指定-a参数了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  # 使用 ping 模块测试所有主机的连通性 [root@master01 ansible]# ansible all -m ping /usr/lib/python2.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (2.2.1) doesn\u0026#39;t match a supported version! RequestsDependencyWarning) 172.31.194.114 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; # 我们看到这一行 ping 返回 pong 说明主机可以连接了。 } 172.31.194.116 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.31.194.117 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 172.31.194.115 | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; }   ","description":"","id":16,"section":"ops","tags":["ansible","自动化运维","DevOps"],"title":"运维自动化神器 Ansible之安装(一)","uri":"http://localhost:1818/ops/devops/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A5%9E%E5%99%A8ansible%E4%B9%8B%E9%83%A8%E7%BD%B2/"},{"content":"一、环境准备 1 2 3 4 5 6 7  # 创建组和用户 groupadd postgre useradd -g postgre -G postgre -d /home/postgresql postgre # 修改用户密码 passwd postgre # web2019+ # 安装依赖包 [root@jiexian /home/postgresql]# yum install -y bzip2 readline-devel zlib-devel   二、源码包下载 1 2  [root@jiexian ~]#cd /home/postgresql/ [root@jiexian /home/postgresql]# wget https://mirrors.tuna.tsinghua.edu.cn/postgresql/source/v12.0/postgresql-12.0.tar.bz2   三、编译安装 1 2 3 4 5 6  [root@jiexian /home/postgresql]# bunzip2 postgresql-12.0.tar.bz2 [root@jiexian /home/postgresql]# tar -xvf ./postgresql-12.0.tar [root@jiexian /home/postgresql]# cd postgresql-12.0/ [root@jiexian /home/postgresql/postgresql-12.0]# ./configure --prefix=/home/postgresql/dbhome [root@jiexian /home/postgresql/postgresql-12.0]# make \u0026amp;\u0026amp; make install   make及make install完成后最后一行输出信息为下即为安装成功\n1  PostgreSQL installation complete.   安装完成后，PostgreSQL安装在如下位置\n1 2 3 4 5 6 7  [root@jiexian /home/postgresql/postgresql-12.0]# cd /home/postgresql/dbhome/ [root@jiexian /home/postgresql/dbhome]# ll 总用量 16 drwxr-xr-x 2 root root 4096 11月 8 21:07 bin drwxr-xr-x 6 root root 4096 11月 8 21:07 include drwxr-xr-x 4 root root 4096 11月 8 21:07 lib drwxr-xr-x 6 root root 4096 11月 8 21:07 share   四、环境变量 1 2 3 4 5 6 7  [root@jiexian ~]# su - postgre [postgre@jiexian ~]$ vi .bash_profile export LD_LBRARY_PATH=$HOME/dbhome/lib:$LD_LIBRARY_PATH export PATH=$HOME/dbhome/bin:$PATH # 加载环境变量 [postgre@jiexian ~]$ source .bash_profile   五、PostgreSQL使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  # 创建PostgreSQL的数据路径 [postgre@jiexian ~]$ mkdir $HOME/data # 初始化数据库 [postgre@jiexian ~]$initdb --locale=C -E UNICODE -D $HOME/data/ The files belonging to this database system will be owned by user \u0026#34;postgre\u0026#34;. This user must also own the server process. The database cluster will be initialized with locale \u0026#34;C\u0026#34;. The default text search configuration will be set to \u0026#34;english\u0026#34;. Data page checksums are disabled. fixing permissions on existing directory /home/postgresql/data ... ok creating subdirectories ... ok selecting dynamic shared memory implementation ... posix selecting default max_connections ... 100 selecting default shared_buffers ... 128MB selecting default time zone ... PRC creating configuration files ... ok running bootstrap script ... ok performing post-bootstrap initialization ... ok syncing data to disk ... ok initdb: warning: enabling \u0026#34;trust\u0026#34; authentication for local connections You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb. Success. You can now start the database server using: pg_ctl -D /home/postgresql/data/ -l logfile start # 初始化完成后，在最后一行会提示我们启动数据库的方法 # 查看一下 $HOME/data 路径中的内容 [postgre@jiexian ~]$cd data [postgre@jiexian ~/data]$ll 总用量 116 drwx------ 5 postgre postgre 4096 11月 8 21:31 base drwx------ 2 postgre postgre 4096 11月 8 21:31 global drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_commit_ts drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_dynshmem -rw------- 1 postgre postgre 4513 11月 8 21:31 pg_hba.conf -rw------- 1 postgre postgre 1636 11月 8 21:31 pg_ident.conf drwx------ 4 postgre postgre 4096 11月 8 21:31 pg_logical drwx------ 4 postgre postgre 4096 11月 8 21:31 pg_multixact drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_notify drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_replslot drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_serial drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_snapshots drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_stat drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_stat_tmp drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_subtrans drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_tblspc drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_twophase -rw------- 1 postgre postgre 3 11月 8 21:31 PG_VERSION drwx------ 3 postgre postgre 4096 11月 8 21:31 pg_wal drwx------ 2 postgre postgre 4096 11月 8 21:31 pg_xact -rw------- 1 postgre postgre 88 11月 8 21:31 postgresql.auto.conf -rw------- 1 postgre postgre 26575 11月 8 21:31 postgresql.conf   六、配置文件 主要修改 $HOME/data 中的 postgresql.conf 及 pg_hba.conf 文件\npostgresql.conf 用来配置数据库实例\npg_hba.conf 用来配置数据库访问授权\npostgresql.conf 将监听地址修改为 ifconfig 中的地址，端口禁用去掉。\nlisten_addresses = '172.16.100.187' # what IP address(es) to listen on;\r# comma-separated list of addresses;\r# defaults to 'localhost'; use '*' for all\r# (change requires restart)\rport = 5432 # (change requires restart)\rpg_hba.conf 将下列内容追加至 pg_hba.conf 最后一行\n1 2  # 允许所有网段访问 PostgreSQL host all all 0.0.0.0/0 trust   七、数据库启停 PostgreSQL启动关闭命令\n1  pg_ctl -D \u0026lt;数据存放路径\u0026gt; [ stop | start ]   示例如下\n1 2 3 4 5 6  [postgre@jiexian ~/data]$pg_ctl -D $HOME/data -l logfile start waiting for server to start.... done server started [postgre@jiexian ~/data]$pg_ctl -D $HOME/data stop waiting for server to shut down.... done server stopped   1 2 3  # 启动时 -l logfile 指明日志输出的位置 [postgre@jiexian ~/data]$ll -rw------- 1 postgre postgre 929 11月 8 21:44 logfile   ","description":"","id":17,"section":"ops","tags":["PostgreSQL","数据库","服务部署"],"title":"源码编译安装 PostgreSQL 12","uri":"http://localhost:1818/ops/deploy/%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85postgresql12/"}]